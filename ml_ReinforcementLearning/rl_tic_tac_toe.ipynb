{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Tic-Tac-Toe with Reinforcement Learning\n",
    "**_Train with SageMaker RL and evaluate interactively within the notebook_**\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Outline\n",
    "\n",
    "1. [Overview](#Overview)\n",
    "1. [Setup](#Setup)\n",
    "1. [Code](#Code)\n",
    "  1. [Environment](#Environment)\n",
    "  1. [Preset](#Preset)\n",
    "  1. [Launcher](#Launcher)\n",
    "1. [Train](#Train)\n",
    "1. [Deploy](#Deploy)\n",
    "  1. [Inference](#Inference)\n",
    "1. [Play](#Play)\n",
    "1. [Wrap Up](#Wrap-Up)\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "Tic-tac-toe is one of the first games children learn to play and was one of the [first computer games ever](https://en.wikipedia.org/wiki/OXO).  Optimal play through exhaustive search is relatively straightforward, however, approaching with a reinforcement learning agent can be educational.\n",
    "\n",
    "This notebook shows how to train a reinforcement learning agent with SageMaker RL and then play locally and interactively within the notebook.  Unlike SageMaker local mode, this method does not require a docker container to run locally, instead using an endpoint and integration with a small Jupyter app.\n",
    "\n",
    "---\n",
    "\n",
    "## Setup\n",
    "\n",
    "Let's start by defining our S3 bucket and and IAM role."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Cell 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.21 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (2.9.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib\n",
    "\n",
    "import sagemaker\n",
    "\n",
    "bucket = 'lab-data-bucket-725001333577-54717fe0'\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the libraries we'll use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Cell 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "from sagemaker.rl import RLEstimator, RLToolkit, RLFramework\n",
    "from tic_tac_toe_game import TicTacToeGame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Code\n",
    "\n",
    "Our tic-tac-toe example requires 3 scripts in order to train our agent using SageMaker RL.  The scripts are placed in the `./src` directory which is sent to the container when the SageMaker training job is initiated.\n",
    "\n",
    "### Environment\n",
    "\n",
    "For our tic-tac-toe use case we'll create a custom Gym environment.  This means we'll specify a Python class which inherits from `gym.Env` and has two methods: `reset()` and `step()`.  These will provide the agent its state, actions, and rewards for learning.  In more detail:\n",
    "\n",
    "The `__init__()` method is called at the beginning of the SageMaker training job and:\n",
    "1. Starts the 3x3 tic-tac-toe board as a NumPy array of zeros\n",
    "1. Prepares the state space as a flattened version of the board (length 9)\n",
    "1. Defines a discrete action space with 9 possible options (one for each place on the board)\n",
    "\n",
    "The `reset()` method is called at the beginning of each episode and:\n",
    "1. Clears the 3x3 board (sets all values to 0)\n",
    "1. Does some minor record-keeping for tracking across tic-tac-toe games\n",
    "\n",
    "The `step()` method is called for each iteration in an episode and:\n",
    "1. Adjusts the board based on the action chosen by the agent based on the previous state\n",
    "1. Generates rewards based on performance\n",
    "1. Automatically chooses the move for the agent's opponent if needed\n",
    "\n",
    "Note:\n",
    "* The opponent has not been programmed for perfect play.  If we taught our agent against a perfect opponent, it would not generalize to scenarios where the rules of perfect play were not followed.\n",
    "* If our agent selects an occupied space, it is given a minor penalty (-0.1) and asked to choose again.  Although the state doesn't change across these steps (meaning the agent's network's prediction should stay the same), randomness in the agent should eventually result in different actions.  However, if the agent chooses an occupied space 10 times in a row, the game is forfeit.  Selecting an action only from available spaces would require more substantial modification than was desired for this example.\n",
    "* Other rewards only occur when a game is completed (+1 for win, 0 for draw, -1 for loss).\n",
    "* The board is saved as a NumPy array where a value of +1 represents our agent's moves (`X`s) and a value of -1 represents the opponent's moves (`O`s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Cell 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtime\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mgym\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mgym\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m spaces\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mTicTacToeEnv\u001b[39;49;00m(gym.Env):\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, opponent=\u001b[33m\"\u001b[39;49;00m\u001b[33mmoderate\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.opponent = opponent\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.episode = \u001b[34m0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.observation_space = spaces.Box(low=-\u001b[34m1\u001b[39;49;00m, high=\u001b[34m1\u001b[39;49;00m, shape=(\u001b[34m9\u001b[39;49;00m,), dtype=np.int)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.action_space = spaces.Discrete(\u001b[34m9\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mreset\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.episode += \u001b[34m1\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.total_reward = \u001b[34m0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.occupied = \u001b[34m0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.board = np.zeros((\u001b[34m3\u001b[39;49;00m, \u001b[34m3\u001b[39;49;00m))\u001b[37m\u001b[39;49;00m\n",
      "        state = \u001b[36mself\u001b[39;49;00m.board.flatten()\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m state\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mstep\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, action):\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# Convert action into board position\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        row = action // \u001b[34m3\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        col = action % \u001b[34m3\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# If agent picks an occupied space repeated end the game and give a penalty\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# Otherwise, give a small penalty and try again\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mif\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.board[row, col] != \u001b[34m0\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[36mself\u001b[39;49;00m.occupied += \u001b[34m1\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mif\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.occupied > \u001b[34m10\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "                reward = -\u001b[34m1\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[36mself\u001b[39;49;00m.total_reward += reward\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[36mself\u001b[39;49;00m.save_board(\u001b[36mself\u001b[39;49;00m.total_reward)\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.board.flatten(), reward, \u001b[34mTrue\u001b[39;49;00m, {\u001b[33m\"\u001b[39;49;00m\u001b[33mreward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: reward}\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34melse\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "                reward = -\u001b[34m0.1\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[36mself\u001b[39;49;00m.total_reward += reward\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.board.flatten(), reward, \u001b[34mFalse\u001b[39;49;00m, {\u001b[33m\"\u001b[39;49;00m\u001b[33mreward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: reward}\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34melse\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[36mself\u001b[39;49;00m.occupied = \u001b[34m0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# Otherwise agent actions action updates the board and check for a win\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.board[row, col] = \u001b[34m1\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mif\u001b[39;49;00m check_win(\u001b[36mself\u001b[39;49;00m.board) == \u001b[34m1\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "            reward = \u001b[34m1\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[36mself\u001b[39;49;00m.total_reward += reward\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[36mself\u001b[39;49;00m.save_board(\u001b[36mself\u001b[39;49;00m.total_reward)\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.board.flatten(), reward, \u001b[34mTrue\u001b[39;49;00m, {\u001b[33m\"\u001b[39;49;00m\u001b[33mreward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: reward}\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# Check if last move\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mif\u001b[39;49;00m (\u001b[36mself\u001b[39;49;00m.board != \u001b[34m0\u001b[39;49;00m).all():\u001b[37m\u001b[39;49;00m\n",
      "            reward = \u001b[34m0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[36mself\u001b[39;49;00m.total_reward += reward\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[36mself\u001b[39;49;00m.save_board(\u001b[36mself\u001b[39;49;00m.total_reward)\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.board.flatten(), reward, \u001b[34mTrue\u001b[39;49;00m, {\u001b[33m\"\u001b[39;49;00m\u001b[33mreward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: reward}\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# If not then opponent moves\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34melse\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[36mself\u001b[39;49;00m.move_opponent()\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mif\u001b[39;49;00m check_win(\u001b[36mself\u001b[39;49;00m.board) == -\u001b[34m1\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "                reward = -\u001b[34m1\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[36mself\u001b[39;49;00m.total_reward += reward\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[36mself\u001b[39;49;00m.save_board(\u001b[36mself\u001b[39;49;00m.total_reward)\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.board.flatten(), reward, \u001b[34mTrue\u001b[39;49;00m, {\u001b[33m\"\u001b[39;49;00m\u001b[33mreward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: reward}\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.board.flatten(), \u001b[34m0\u001b[39;49;00m, \u001b[34mFalse\u001b[39;49;00m, {\u001b[33m\"\u001b[39;49;00m\u001b[33mreward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[34m0\u001b[39;49;00m}\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mmove_opponent\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mif\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.opponent == \u001b[33m\"\u001b[39;49;00m\u001b[33mrandom\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "            options = np.argwhere(\u001b[36mself\u001b[39;49;00m.board == \u001b[34m0\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "            idx = np.random.randint(options.shape[\u001b[34m0\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[36mself\u001b[39;49;00m.board[\u001b[36mtuple\u001b[39;49;00m(options[idx])] = -\u001b[34m1\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34melif\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.opponent == \u001b[33m\"\u001b[39;49;00m\u001b[33mmoderate\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "            move = \u001b[34mNone\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "            options = np.argwhere(\u001b[36mself\u001b[39;49;00m.board == \u001b[34m0\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mif\u001b[39;49;00m np.random.rand() < \u001b[34m0.1\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "                idx = np.random.randint(options.shape[\u001b[34m0\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[36mself\u001b[39;49;00m.board[\u001b[36mtuple\u001b[39;49;00m(options[idx])] = -\u001b[34m1\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34melse\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[37m# Check if there's a next move that could win\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[34mfor\u001b[39;49;00m o \u001b[35min\u001b[39;49;00m options:\u001b[37m\u001b[39;49;00m\n",
      "                    board = \u001b[36mself\u001b[39;49;00m.board.copy()\u001b[37m\u001b[39;49;00m\n",
      "                    board[\u001b[36mtuple\u001b[39;49;00m(o)] = -\u001b[34m1\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "                    \u001b[34mif\u001b[39;49;00m check_win(board) == -\u001b[34m1\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "                        move = \u001b[36mtuple\u001b[39;49;00m(o)\u001b[37m\u001b[39;49;00m\n",
      "                        \u001b[34mbreak\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[37m# Otherwise check for a block\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[34mif\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m move:\u001b[37m\u001b[39;49;00m\n",
      "                    \u001b[34mfor\u001b[39;49;00m o \u001b[35min\u001b[39;49;00m options:\u001b[37m\u001b[39;49;00m\n",
      "                        board = \u001b[36mself\u001b[39;49;00m.board.copy()\u001b[37m\u001b[39;49;00m\n",
      "                        board[\u001b[36mtuple\u001b[39;49;00m(o)] = \u001b[34m1\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "                        \u001b[34mif\u001b[39;49;00m check_win(board) == \u001b[34m1\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "                            move = \u001b[36mtuple\u001b[39;49;00m(o)\u001b[37m\u001b[39;49;00m\n",
      "                            \u001b[34mbreak\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[37m# Otherwise, take a random option\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[34mif\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m move:\u001b[37m\u001b[39;49;00m\n",
      "                    idx = np.random.randint(options.shape[\u001b[34m0\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "                    move = \u001b[36mtuple\u001b[39;49;00m(options[idx])\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[36mself\u001b[39;49;00m.board[move] = -\u001b[34m1\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32msave_board\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, reward, path=\u001b[33m\"\u001b[39;49;00m\u001b[33m/opt/ml/output/data/\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "        np.save(\u001b[37m\u001b[39;49;00m\n",
      "            os.path.join(path, \u001b[33m\"\u001b[39;49;00m\u001b[33mepisode_\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m_reward_\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m.npy\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(\u001b[36mself\u001b[39;49;00m.episode, reward)), \u001b[36mself\u001b[39;49;00m.board\u001b[37m\u001b[39;49;00m\n",
      "        )\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mcheck_win\u001b[39;49;00m(board):\u001b[37m\u001b[39;49;00m\n",
      "    v = board.sum(axis=\u001b[34m0\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    h = board.sum(axis=\u001b[34m1\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    dd = board[\u001b[34m0\u001b[39;49;00m, \u001b[34m0\u001b[39;49;00m] + board[\u001b[34m1\u001b[39;49;00m, \u001b[34m1\u001b[39;49;00m] + board[\u001b[34m2\u001b[39;49;00m, \u001b[34m2\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "    du = board[\u001b[34m2\u001b[39;49;00m, \u001b[34m0\u001b[39;49;00m] + board[\u001b[34m1\u001b[39;49;00m, \u001b[34m1\u001b[39;49;00m] + board[\u001b[34m0\u001b[39;49;00m, \u001b[34m2\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m \u001b[36mmax\u001b[39;49;00m(v.max(), h.max()) == \u001b[34m3\u001b[39;49;00m \u001b[35mor\u001b[39;49;00m dd == \u001b[34m3\u001b[39;49;00m \u001b[35mor\u001b[39;49;00m du == \u001b[34m3\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[34m1\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34melif\u001b[39;49;00m \u001b[36mmin\u001b[39;49;00m(v.min(), h.min()) == -\u001b[34m3\u001b[39;49;00m \u001b[35mor\u001b[39;49;00m dd == -\u001b[34m3\u001b[39;49;00m \u001b[35mor\u001b[39;49;00m du == -\u001b[34m3\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m -\u001b[34m1\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34melse\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[34m0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize ./src/tic_tac_toe.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preset\n",
    "\n",
    "The preset file specifies Coach parameters used by our reinforcement learning agent.  For this problem we'll use a [Clipped PPO algorithm](https://nervanasystems.github.io/coach/components/agents/policy_optimization/cppo.html).  We have kept the preset file deliberately spartan, deferring to defaults for most parameters, in order to focus on just the key components.  Performance of our agent could likely be improved with increased tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Cell 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mrl_coach\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36magents\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mclipped_ppo_agent\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m ClippedPPOAgentParameters\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mrl_coach\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mbase_parameters\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m PresetValidationParameters, VisualizationParameters\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mrl_coach\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mcore_types\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m EnvironmentEpisodes, EnvironmentSteps, TrainingSteps\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mrl_coach\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36menvironments\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mgym_environment\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m GymVectorEnvironment\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mrl_coach\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mgraph_managers\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mbasic_rl_graph_manager\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m BasicRLGraphManager\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mrl_coach\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mgraph_managers\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mgraph_manager\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m ScheduleParameters\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m####################\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# Graph Scheduling #\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m####################\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "schedule_params = ScheduleParameters()\u001b[37m\u001b[39;49;00m\n",
      "schedule_params.improve_steps = TrainingSteps(\u001b[34m20000\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "schedule_params.steps_between_evaluation_periods = EnvironmentSteps(\u001b[34m1000\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "schedule_params.evaluation_steps = EnvironmentEpisodes(\u001b[34m5\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "schedule_params.heatup_steps = EnvironmentSteps(\u001b[34m0\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#########\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# Agent #\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#########\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "agent_params = ClippedPPOAgentParameters()\u001b[37m\u001b[39;49;00m\n",
      "agent_params.network_wrappers[\u001b[33m\"\u001b[39;49;00m\u001b[33mmain\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m].middleware_parameters.activation_function = \u001b[33m\"\u001b[39;49;00m\u001b[33mrelu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "agent_params.network_wrappers[\u001b[33m\"\u001b[39;49;00m\u001b[33mmain\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m].input_embedders_parameters[\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[33m\"\u001b[39;49;00m\u001b[33mobservation\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "].activation_function = \u001b[33m\"\u001b[39;49;00m\u001b[33mrelu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "agent_params.network_wrappers[\u001b[33m\"\u001b[39;49;00m\u001b[33mmain\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m].learning_rate = \u001b[34m0.001\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m###############\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# Environment #\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m###############\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "env_params = GymVectorEnvironment(level=\u001b[33m\"\u001b[39;49;00m\u001b[33mtic_tac_toe:TicTacToeEnv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m########\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# Test #\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m########\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "preset_validation_params = PresetValidationParameters()\u001b[37m\u001b[39;49;00m\n",
      "preset_validation_params.test = \u001b[34mTrue\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "graph_manager = BasicRLGraphManager(\u001b[37m\u001b[39;49;00m\n",
      "    agent_params=agent_params,\u001b[37m\u001b[39;49;00m\n",
      "    env_params=env_params,\u001b[37m\u001b[39;49;00m\n",
      "    schedule_params=schedule_params,\u001b[37m\u001b[39;49;00m\n",
      "    vis_params=VisualizationParameters(),\u001b[37m\u001b[39;49;00m\n",
      "    preset_validation_params=preset_validation_params,\u001b[37m\u001b[39;49;00m\n",
      ")\u001b[37m\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize ./src/preset.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launcher\n",
    "\n",
    "The launcher is a script used by Amazon SageMaker to drive the training job on the SageMaker RL container.  We have kept it minimal, only specifying the name of the preset file to be used for the training job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Cell 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker_rl\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mcoach_launcher\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m SageMakerCoachPresetLauncher\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mMyLauncher\u001b[39;49;00m(SageMakerCoachPresetLauncher):\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mdefault_preset_name\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[33m\"\"\"This points to a .py file that configures everything about the RL job.\u001b[39;49;00m\n",
      "\u001b[33m        It can be overridden at runtime by specifying the RLCOACH_PRESET hyperparameter.\u001b[39;49;00m\n",
      "\u001b[33m        \"\"\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mpreset\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "    MyLauncher.train_main()\u001b[37m\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize ./src/train-coach.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Train\n",
    "\n",
    "Now, let's kick off the training job in Amazon SageMaker.  This call can include hyperparameters that overwrite values in `train-coach.py` or `preset.py`, but in our case, we've limited to defining:\n",
    "1. The location of our agent code `./src` and dependencies in `common`.\n",
    "1. Which RL and DL framework to use (SageMaker also supports [Ray RLlib](https://ray.readthedocs.io/en/latest/rllib.html) and Coach TensorFlow).\n",
    "1. The IAM role granted permissions to our data in S3 and ability to create SageMaker training jobs.\n",
    "1. Training job hardware specifications (in this case just 1 ml.m4.xlarge instance).\n",
    "1. Output path for our checkpoints and saved episodes.\n",
    "1. A single hyperparameter specifying that we would like our agent's network to be output (in this case as an ONNX model)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Cell 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n",
      "INFO:sagemaker:Creating training-job with name: DEMO-rl-tic-tac-toe-2024-08-15-15-30-30-258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 15:30:30 Starting - Starting the training job......\n",
      "2024-08-15 15:31:08 Starting - Preparing the instances for training...\n",
      "2024-08-15 15:31:56 Downloading - Downloading input data...\n",
      "2024-08-15 15:32:22 Downloading - Downloading the training image...\n",
      "2024-08-15 15:32:47 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2024-08-15 15:32:57,724 sagemaker-containers INFO     Imported framework sagemaker_mxnet_container.training\u001b[0m\n",
      "\u001b[34m2024-08-15 15:32:57,729 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-08-15 15:32:57,744 sagemaker_mxnet_container.training INFO     MXNet training environment: {'SM_HOSTS': '[\"algo-1\"]', 'SM_MODEL_DIR': '/opt/ml/model', 'SM_CHANNELS': '[]', 'SM_HP_SAVE_MODEL': '1', 'SM_RESOURCE_CONFIG': '{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m4.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m4.xlarge\"}],\"network_interface_name\":\"eth0\"}', 'SM_USER_ENTRY_POINT': 'train-coach.py', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'SM_NUM_GPUS': '0', 'SM_HPS': '{\"save_model\":1}', 'SM_MODULE_DIR': 's3://lab-data-bucket-725001333577-54717fe0/DEMO-rl-tic-tac-toe-2024-08-15-15-30-30-258/source/sourcedir.tar.gz', 'SM_INPUT_DATA_CONFIG': '{}', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{\"sagemaker_estimator\":\"RLEstimator\"},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"save_model\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"job_name\":\"DEMO-rl-tic-tac-toe-2024-08-15-15-30-30-258\",\"log_level\":20,\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://lab-data-bucket-725001333577-54717fe0/DEMO-rl-tic-tac-toe-2024-08-15-15-30-30-258/source/sourcedir.tar.gz\",\"module_name\":\"train-coach\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m4.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m4.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train-coach.py\"}', 'SM_MODULE_NAME': 'train-coach', 'SM_FRAMEWORK_MODULE': 'sagemaker_mxnet_container.training:main', 'SM_USER_ARGS': '[\"--save_model\",\"1\"]', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_NUM_CPUS': '4', 'SM_LOG_LEVEL': '20', 'SM_INPUT_DIR': '/opt/ml/input', 'SM_CURRENT_HOST': 'algo-1', 'SM_FRAMEWORK_PARAMS': '{\"sagemaker_estimator\":\"RLEstimator\"}'}\u001b[0m\n",
      "\u001b[34m2024-08-15 15:32:57,907 sagemaker-containers INFO     Module train-coach does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2024-08-15 15:32:57,907 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2024-08-15 15:32:57,908 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2024-08-15 15:32:57,908 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install -U . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: train-coach\n",
      "  Running setup.py bdist_wheel for train-coach: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for train-coach: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-8q8rw6nm/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[34mSuccessfully built train-coach\u001b[0m\n",
      "\u001b[34mInstalling collected packages: train-coach\u001b[0m\n",
      "\u001b[34mSuccessfully installed train-coach-1.0.0\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 20.3.4 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2024-08-15 15:32:59,481 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-08-15 15:32:59,496 sagemaker-containers INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"module_dir\": \"s3://lab-data-bucket-725001333577-54717fe0/DEMO-rl-tic-tac-toe-2024-08-15-15-30-30-258/source/sourcedir.tar.gz\",\n",
      "    \"num_gpus\": 0,\n",
      "    \"input_data_config\": {},\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_estimator\": \"RLEstimator\"\n",
      "    },\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"module_name\": \"train-coach\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"user_entry_point\": \"train-coach.py\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"resource_config\": {\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"current_instance_type\": \"ml.m4.xlarge\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m4.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\",\n",
      "        \"current_host\": \"algo-1\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"log_level\": 20,\n",
      "    \"framework_module\": \"sagemaker_mxnet_container.training:main\",\n",
      "    \"hyperparameters\": {\n",
      "        \"save_model\": 1\n",
      "    },\n",
      "    \"num_cpus\": 4,\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"job_name\": \"DEMO-rl-tic-tac-toe-2024-08-15-15-30-30-258\",\n",
      "    \"input_dir\": \"/opt/ml/input\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python35.zip:/usr/lib/python3.5:/usr/lib/python3.5/plat-x86_64-linux-gnu:/usr/lib/python3.5/lib-dynload:/usr/local/lib/python3.5/dist-packages:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_HP_SAVE_MODEL=1\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m4.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m4.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train-coach.py\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://lab-data-bucket-725001333577-54717fe0/DEMO-rl-tic-tac-toe-2024-08-15-15-30-30-258/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_estimator\":\"RLEstimator\"},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"save_model\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"job_name\":\"DEMO-rl-tic-tac-toe-2024-08-15-15-30-30-258\",\"log_level\":20,\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://lab-data-bucket-725001333577-54717fe0/DEMO-rl-tic-tac-toe-2024-08-15-15-30-30-258/source/sourcedir.tar.gz\",\"module_name\":\"train-coach\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m4.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m4.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train-coach.py\"}\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_mxnet_container.training:main\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--save_model\",\"1\"]\u001b[0m\n",
      "\u001b[34mSM_HPS={\"save_model\":1}\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_estimator\":\"RLEstimator\"}\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train-coach\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m train-coach --save_model 1\u001b[0m\n",
      "\u001b[34m#033[93mWarning: failed to import the following packages - tensorflow#033[0m\u001b[0m\n",
      "\u001b[34mLoading preset preset from /opt/ml/code\u001b[0m\n",
      "\u001b[34m## Creating graph - name: BasicRLGraphManager\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.5/dist-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\u001b[0m\n",
      "\u001b[34m## Creating agent - name: agent\u001b[0m\n",
      "\u001b[34mRequested devices [gpu(0)] not available. Default to CPU context.\u001b[0m\n",
      "\u001b[34mRequested devices [gpu(0)] not available. Default to CPU context.\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.5/dist-packages/mxnet/gluon/block.py:303: UserWarning: \"PPOHead._loss\" is an unregistered container with Blocks. Note that Blocks inside the list, tuple or dict will not be registered automatically. Make sure to register them using register_child() or switching to nn.Sequential/nn.HybridSequential instead. \n",
      "  ret.update(cld.collect_params(select=select))\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.5/dist-packages/mxnet/gluon/block.py:303: UserWarning: \"PPOHead._loss\" is an unregistered container with Blocks. Note that Blocks inside the list, tuple or dict will not be registered automatically. Make sure to register them using register_child() or switching to nn.Sequential/nn.HybridSequential instead. \n",
      "  ret.update(cld.collect_params(select=select))\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.5/dist-packages/mxnet/gluon/block.py:303: UserWarning: \"PPOHead._loss\" is an unregistered container with Blocks. Note that Blocks inside the list, tuple or dict will not be registered automatically. Make sure to register them using register_child() or switching to nn.Sequential/nn.HybridSequential instead. \n",
      "  ret.update(cld.collect_params(select=select))\u001b[0m\n",
      "\u001b[34m## Starting to improve simple_rl_graph task index 0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1, Total reward=-1.4, Steps=8, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2, Total reward=-1.1, Steps=12, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=3, Total reward=-0.4, Steps=21, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=4, Total reward=-1.1, Steps=25, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=5, Total reward=0.8, Steps=31, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=6, Total reward=-1.1, Steps=35, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=7, Total reward=-1.4, Steps=42, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=8, Total reward=-0.6, Steps=53, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=9, Total reward=-1.1, Steps=57, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=10, Total reward=-1.3, Steps=63, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=11, Total reward=0.8, Steps=69, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=12, Total reward=-1.3, Steps=76, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=13, Total reward=-0.9, Steps=90, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=14, Total reward=-1.2, Steps=96, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=15, Total reward=-1.4, Steps=104, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=16, Total reward=-1.2, Steps=109, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=17, Total reward=-1, Steps=112, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=18, Total reward=-1, Steps=116, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=19, Total reward=-0.5, Steps=126, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=20, Total reward=-0.1, Steps=142, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=21, Total reward=-2.4, Steps=161, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=22, Total reward=-1.6, Steps=170, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=23, Total reward=1, Steps=174, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=24, Total reward=-1, Steps=177, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=25, Total reward=-0.9, Steps=191, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=26, Total reward=-2.4, Steps=210, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=27, Total reward=-0.2, Steps=217, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=28, Total reward=-1, Steps=220, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=29, Total reward=-1, Steps=223, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=30, Total reward=-1, Steps=226, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=31, Total reward=-1.1, Steps=242, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=32, Total reward=0.0, Steps=257, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=33, Total reward=-1.1, Steps=262, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=34, Total reward=-1.3, Steps=268, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=35, Total reward=-1.6, Steps=277, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=36, Total reward=-1, Steps=280, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=37, Total reward=-1, Steps=284, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=38, Total reward=-1.3, Steps=291, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=39, Total reward=-1.1, Steps=295, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=40, Total reward=-1.1, Steps=299, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=41, Total reward=-2.3, Steps=317, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=42, Total reward=-1.1, Steps=321, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=43, Total reward=-1, Steps=324, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=44, Total reward=0.5, Steps=333, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=45, Total reward=-2.1, Steps=348, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=46, Total reward=-1.1, Steps=364, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=47, Total reward=-1.1, Steps=369, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=48, Total reward=-2.0, Steps=384, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=49, Total reward=-1.3, Steps=391, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=50, Total reward=-1.1, Steps=407, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=51, Total reward=-1.1, Steps=423, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=52, Total reward=-1, Steps=426, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=53, Total reward=-1.2, Steps=432, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=54, Total reward=-2.5, Steps=452, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=55, Total reward=-1.3, Steps=459, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=56, Total reward=-1, Steps=463, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=57, Total reward=-1.9, Steps=476, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=58, Total reward=-1.3, Steps=483, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=59, Total reward=-1, Steps=487, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=60, Total reward=-1, Steps=490, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=61, Total reward=-1.1, Steps=494, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=62, Total reward=-1.1, Steps=510, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=63, Total reward=-1.1, Steps=526, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=64, Total reward=-2.3, Steps=544, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=65, Total reward=-1.2, Steps=550, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=66, Total reward=-1.2, Steps=567, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=67, Total reward=-1, Steps=570, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=68, Total reward=-1.1, Steps=575, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=69, Total reward=0.9, Steps=579, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=70, Total reward=-1.3, Steps=597, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=71, Total reward=-0.1, Steps=603, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=72, Total reward=-1.1, Steps=607, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=73, Total reward=-1.1, Steps=612, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=74, Total reward=-1.2, Steps=618, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=75, Total reward=-1, Steps=621, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=76, Total reward=-1.1, Steps=625, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=77, Total reward=-0.4, Steps=634, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=78, Total reward=-1.1, Steps=638, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=79, Total reward=0.8, Steps=644, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=80, Total reward=-0.9, Steps=658, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=81, Total reward=-1.2, Steps=664, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=82, Total reward=-1.2, Steps=669, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=83, Total reward=-1.1, Steps=685, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=84, Total reward=-0.3, Steps=693, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=85, Total reward=-0.9, Steps=707, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=86, Total reward=-0.7, Steps=719, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=87, Total reward=0.8, Steps=725, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=88, Total reward=-1.7, Steps=736, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=89, Total reward=-2.1, Steps=751, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=90, Total reward=-1.1, Steps=755, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=91, Total reward=-1.2, Steps=760, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=92, Total reward=-1.1, Steps=765, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=93, Total reward=-1.1, Steps=769, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=94, Total reward=-1.3, Steps=776, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=95, Total reward=1, Steps=779, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=96, Total reward=-1.3, Steps=786, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=97, Total reward=-2.0, Steps=801, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=98, Total reward=-1.2, Steps=807, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=99, Total reward=-1, Steps=810, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=100, Total reward=-1.1, Steps=814, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=101, Total reward=0.9, Steps=819, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=102, Total reward=-1.4, Steps=838, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=103, Total reward=-1, Steps=841, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=104, Total reward=-1.4, Steps=849, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=105, Total reward=-1.1, Steps=854, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=106, Total reward=-1.6, Steps=864, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=107, Total reward=-1, Steps=867, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=108, Total reward=-1.2, Steps=873, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=109, Total reward=-1, Steps=876, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=110, Total reward=-1.1, Steps=881, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=111, Total reward=-1.4, Steps=889, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=112, Total reward=-0.9, Steps=903, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=113, Total reward=-2.3, Steps=921, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=114, Total reward=-0.4, Steps=930, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=115, Total reward=-1, Steps=933, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=116, Total reward=-0.4, Steps=942, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=117, Total reward=0.0, Steps=957, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=118, Total reward=-1.1, Steps=962, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=119, Total reward=-1.4, Steps=970, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=120, Total reward=-1.1, Steps=975, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=121, Total reward=0.1, Steps=989, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=122, Total reward=-1.1, Steps=993, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=123, Total reward=-1, Steps=996, Training iteration=0\u001b[0m\n",
      "\u001b[34m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=123, Total reward=-2.0, Steps=1000, Training iteration=0\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=123, Total reward=-2.0, Steps=1000, Training iteration=0\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=123, Total reward=-2.0, Steps=1000, Training iteration=0\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=123, Total reward=-1, Steps=1000, Training iteration=0\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=123, Total reward=-1, Steps=1000, Training iteration=0\u001b[0m\n",
      "\u001b[34m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = -1.6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=124, Total reward=-1.8, Steps=1012, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=125, Total reward=-1, Steps=1015, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=126, Total reward=-1.2, Steps=1020, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=127, Total reward=-1.1, Steps=1024, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=128, Total reward=-1.1, Steps=1028, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=129, Total reward=-0.5, Steps=1038, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=130, Total reward=-1.2, Steps=1043, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=131, Total reward=-1.5, Steps=1051, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=132, Total reward=-0.3, Steps=1059, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=133, Total reward=-1, Steps=1062, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=134, Total reward=-2.0, Steps=1077, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=135, Total reward=-1, Steps=1080, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=136, Total reward=-1.1, Steps=1084, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=137, Total reward=-0.7, Steps=1096, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=138, Total reward=-1.7, Steps=1107, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=139, Total reward=-1.1, Steps=1111, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=140, Total reward=0.8, Steps=1117, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=141, Total reward=-1, Steps=1120, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=142, Total reward=-1.1, Steps=1124, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=143, Total reward=-1.1, Steps=1128, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=144, Total reward=0.8, Steps=1134, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=145, Total reward=-1.1, Steps=1150, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=146, Total reward=-1.1, Steps=1154, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=147, Total reward=-1.2, Steps=1160, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=148, Total reward=0.5, Steps=1169, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=149, Total reward=-1, Steps=1173, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=150, Total reward=-1, Steps=1176, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=151, Total reward=-1, Steps=1179, Training iteration=0\u001b[0m\n",
      "\u001b[34mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/0_Step-1179.ckpt.main_level.agent.main.online.onnx', '/opt/ml/output/data/checkpoint/0_Step-1179.ckpt.main_level.agent.main.online']\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=152, Total reward=-1.3, Steps=1185, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=153, Total reward=-1.2, Steps=1191, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=154, Total reward=-1.4, Steps=1198, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=155, Total reward=-1.1, Steps=1203, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=156, Total reward=-1.1, Steps=1207, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=157, Total reward=-1, Steps=1210, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=158, Total reward=-1.1, Steps=1226, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=159, Total reward=-1, Steps=1229, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=160, Total reward=-1.6, Steps=1239, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=161, Total reward=-1, Steps=1242, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=162, Total reward=-1.2, Steps=1248, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=163, Total reward=-2.7, Steps=1270, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=164, Total reward=-1.2, Steps=1276, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=165, Total reward=-1.3, Steps=1283, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=166, Total reward=-1.2, Steps=1288, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=167, Total reward=-2.0, Steps=1303, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=168, Total reward=-1.1, Steps=1307, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=169, Total reward=-1.4, Steps=1315, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=170, Total reward=-2.3, Steps=1333, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=171, Total reward=-2.0, Steps=1348, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=172, Total reward=0.6, Steps=1356, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=173, Total reward=-1.4, Steps=1375, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=174, Total reward=-1.2, Steps=1381, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=175, Total reward=-1, Steps=1384, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=176, Total reward=-1, Steps=1387, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=177, Total reward=-0.8, Steps=1400, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=178, Total reward=-1, Steps=1403, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=179, Total reward=0.9, Steps=1408, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=180, Total reward=-1.2, Steps=1413, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=181, Total reward=-1, Steps=1416, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=182, Total reward=-1.1, Steps=1442, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=183, Total reward=-1, Steps=1445, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=184, Total reward=-1, Steps=1448, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=185, Total reward=0.9, Steps=1453, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=186, Total reward=-1.4, Steps=1461, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=187, Total reward=-1.1, Steps=1465, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=188, Total reward=-1, Steps=1468, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=189, Total reward=-1.2, Steps=1473, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=190, Total reward=-1.1, Steps=1477, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=191, Total reward=-0.4, Steps=1486, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=192, Total reward=1, Steps=1490, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=193, Total reward=-1.0, Steps=1505, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=194, Total reward=-1, Steps=1508, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=195, Total reward=-0.8, Steps=1521, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=196, Total reward=-1.1, Steps=1525, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=197, Total reward=-0.6, Steps=1536, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=198, Total reward=-1.1, Steps=1540, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=199, Total reward=-1, Steps=1543, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=200, Total reward=-2.3, Steps=1561, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=201, Total reward=-1.2, Steps=1567, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=202, Total reward=-1.1, Steps=1571, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=203, Total reward=-1.1, Steps=1575, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=204, Total reward=-0.5, Steps=1585, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=205, Total reward=-1.1, Steps=1590, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=206, Total reward=-2.1, Steps=1605, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=207, Total reward=-1.0, Steps=1620, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=208, Total reward=0.7, Steps=1627, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=209, Total reward=-1.1, Steps=1631, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=210, Total reward=0.4, Steps=1641, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=211, Total reward=0.6, Steps=1649, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=212, Total reward=-1, Steps=1652, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=213, Total reward=-1, Steps=1655, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=214, Total reward=-1, Steps=1658, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=215, Total reward=-1.2, Steps=1663, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=216, Total reward=-1.1, Steps=1667, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=217, Total reward=-1.2, Steps=1672, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=218, Total reward=-1.1, Steps=1677, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=219, Total reward=0.8, Steps=1684, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=220, Total reward=-1.4, Steps=1692, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=221, Total reward=-0.2, Steps=1699, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=222, Total reward=-1, Steps=1702, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=223, Total reward=-1.1, Steps=1706, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=224, Total reward=-1, Steps=1709, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=225, Total reward=-1.5, Steps=1717, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=226, Total reward=-1.3, Steps=1723, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=227, Total reward=-2.8, Steps=1746, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=228, Total reward=-1.1, Steps=1750, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=229, Total reward=0.1, Steps=1764, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=230, Total reward=-2.1, Steps=1780, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=231, Total reward=-1.3, Steps=1786, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=232, Total reward=1, Steps=1790, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=233, Total reward=-1.2, Steps=1795, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=234, Total reward=-1.2, Steps=1801, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=235, Total reward=-1.1, Steps=1806, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=236, Total reward=-1, Steps=1809, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=237, Total reward=-1.1, Steps=1813, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=238, Total reward=-1.2, Steps=1819, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=239, Total reward=-1.7, Steps=1830, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=240, Total reward=-1.5, Steps=1838, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=241, Total reward=-1.2, Steps=1844, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=242, Total reward=-1.6, Steps=1854, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=243, Total reward=-1.6, Steps=1864, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=244, Total reward=-2.1, Steps=1880, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=245, Total reward=0.8, Steps=1886, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=246, Total reward=-1.8, Steps=1898, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=247, Total reward=-1.1, Steps=1914, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=248, Total reward=-1.1, Steps=1918, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=249, Total reward=-1, Steps=1921, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=250, Total reward=-1.6, Steps=1931, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=251, Total reward=-1.1, Steps=1935, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=252, Total reward=0.0, Steps=1950, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=253, Total reward=0.6, Steps=1959, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=254, Total reward=-1, Steps=1962, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=255, Total reward=-1, Steps=1966, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=256, Total reward=-1.1, Steps=1971, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=257, Total reward=-0.5, Steps=1981, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=258, Total reward=-1.2, Steps=1986, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=259, Total reward=0.9, Steps=1991, Training iteration=0\u001b[0m\n",
      "\u001b[34m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.5/dist-packages/mxnet/gluon/block.py:303: UserWarning: \"PPOHead._loss\" is an unregistered container with Blocks. Note that Blocks inside the list, tuple or dict will not be registered automatically. Make sure to register them using register_child() or switching to nn.Sequential/nn.HybridSequential instead. \n",
      "  ret.update(cld.collect_params(select=select))\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=259, Total reward=-2.0, Steps=2000, Training iteration=0\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=259, Total reward=-2.0, Steps=2000, Training iteration=0\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=259, Total reward=-1, Steps=2000, Training iteration=0\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=259, Total reward=-2.0, Steps=2000, Training iteration=0\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=259, Total reward=-2.0, Steps=2000, Training iteration=0\u001b[0m\n",
      "\u001b[34m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = -1.8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=260, Total reward=-1.2, Steps=2006, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=261, Total reward=-1.1, Steps=2010, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=262, Total reward=-1.5, Steps=2018, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=263, Total reward=-1, Steps=2021, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=264, Total reward=-2.1, Steps=2037, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=265, Total reward=-1, Steps=2040, Training iteration=0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=266, Total reward=-2.0, Steps=2055, Training iteration=0\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.5/dist-packages/rl_coach/architectures/mxnet_components/heads/head.py:95: UserWarning: Parameter clippedppolossdiscrete0_kl_coefficient is not used by any computation. Is this intended?\n",
      "  outputs = super(HeadLoss, self).forward(*args)\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.0007706793840043247, KL divergence=[0.], Entropy=[-0.02196827], training epoch=0, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.0035725149791687727, KL divergence=[0.], Entropy=[-0.02191064], training epoch=1, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.020346758887171745, KL divergence=[0.], Entropy=[-0.02189616], training epoch=2, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.01980607397854328, KL divergence=[0.], Entropy=[-0.0218406], training epoch=3, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.02574128843843937, KL divergence=[0.], Entropy=[-0.02184138], training epoch=4, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.027952896431088448, KL divergence=[0.], Entropy=[-0.02180052], training epoch=5, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.03561311215162277, KL divergence=[0.], Entropy=[-0.02180895], training epoch=6, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.03981853649020195, KL divergence=[0.], Entropy=[-0.02176462], training epoch=7, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.04782024770975113, KL divergence=[0.], Entropy=[-0.02176911], training epoch=8, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.04651501402258873, KL divergence=[0.], Entropy=[-0.02174382], training epoch=9, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/1_Step-2055.ckpt.main_level.agent.main.online.onnx', '/opt/ml/output/data/checkpoint/1_Step-2055.ckpt.main_level.agent.main.online']\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=267, Total reward=-1, Steps=2058, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=268, Total reward=-1.1, Steps=2062, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=269, Total reward=-1.5, Steps=2071, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=270, Total reward=0.3, Steps=2083, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=271, Total reward=-1, Steps=2087, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=272, Total reward=-1.5, Steps=2096, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=273, Total reward=-1, Steps=2099, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=274, Total reward=-0.6, Steps=2110, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=275, Total reward=-1.3, Steps=2116, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=276, Total reward=0.9, Steps=2121, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=277, Total reward=-0.6, Steps=2132, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=278, Total reward=-1.9, Steps=2156, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=279, Total reward=-1.1, Steps=2160, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=280, Total reward=-0.8, Steps=2173, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=281, Total reward=-1, Steps=2176, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=282, Total reward=-1.2, Steps=2181, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=283, Total reward=-0.4, Steps=2190, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=284, Total reward=-0.2, Steps=2197, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=285, Total reward=-0.6, Steps=2208, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=286, Total reward=0.9, Steps=2213, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=287, Total reward=-1.6, Steps=2223, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=288, Total reward=-1.1, Steps=2227, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=289, Total reward=-1.1, Steps=2231, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=290, Total reward=-1, Steps=2234, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=291, Total reward=-1.2, Steps=2239, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=292, Total reward=-0.9, Steps=2253, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=293, Total reward=-0.2, Steps=2260, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=294, Total reward=-1.5, Steps=2269, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=295, Total reward=-1.2, Steps=2275, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=296, Total reward=-1, Steps=2279, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=297, Total reward=-3.1, Steps=2305, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=298, Total reward=0.8, Steps=2311, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=299, Total reward=-1.5, Steps=2320, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=300, Total reward=-1, Steps=2324, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=301, Total reward=-1, Steps=2327, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=302, Total reward=-1.3, Steps=2345, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=303, Total reward=-2.1, Steps=2361, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=304, Total reward=-1, Steps=2365, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=305, Total reward=-1, Steps=2368, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=306, Total reward=-1.1, Steps=2372, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=307, Total reward=-1, Steps=2375, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=308, Total reward=-1.1, Steps=2379, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=309, Total reward=-1.1, Steps=2383, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=310, Total reward=-1, Steps=2386, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=311, Total reward=-0.4, Steps=2395, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=312, Total reward=-1.3, Steps=2402, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=313, Total reward=-1.1, Steps=2406, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=314, Total reward=-1.3, Steps=2413, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=315, Total reward=-1, Steps=2416, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=316, Total reward=-0.2, Steps=2423, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=317, Total reward=-1, Steps=2427, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=318, Total reward=-1.1, Steps=2431, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=319, Total reward=-1, Steps=2434, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=320, Total reward=-1, Steps=2437, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=321, Total reward=-1.4, Steps=2445, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=322, Total reward=-1, Steps=2448, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=323, Total reward=-2.7, Steps=2470, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=324, Total reward=-1.2, Steps=2476, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=325, Total reward=-1.4, Steps=2483, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=326, Total reward=-1.3, Steps=2489, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=327, Total reward=-0.5, Steps=2499, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=328, Total reward=-1, Steps=2503, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=329, Total reward=-1.0, Steps=2518, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=330, Total reward=0.8, Steps=2524, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=331, Total reward=-1.3, Steps=2542, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=332, Total reward=-1.4, Steps=2550, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=333, Total reward=-1.3, Steps=2557, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=334, Total reward=-1.1, Steps=2561, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=335, Total reward=-1, Steps=2564, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=336, Total reward=0.2, Steps=2576, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=337, Total reward=-1.3, Steps=2583, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=338, Total reward=0.2, Steps=2596, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=339, Total reward=-1.8, Steps=2608, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=340, Total reward=1, Steps=2612, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=341, Total reward=-1, Steps=2615, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=342, Total reward=-1.1, Steps=2619, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=343, Total reward=-1.2, Steps=2624, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=344, Total reward=-1, Steps=2628, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=345, Total reward=-0.1, Steps=2634, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=346, Total reward=-1.4, Steps=2642, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=347, Total reward=-1, Steps=2645, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=348, Total reward=-1.1, Steps=2650, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=349, Total reward=-1.1, Steps=2655, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=350, Total reward=-1, Steps=2658, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=351, Total reward=-1.2, Steps=2663, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=352, Total reward=-1, Steps=2666, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=353, Total reward=-0.6, Steps=2677, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=354, Total reward=-0.4, Steps=2686, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=355, Total reward=-2.2, Steps=2703, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=356, Total reward=-1.4, Steps=2711, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=357, Total reward=-2.4, Steps=2730, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=358, Total reward=-1.1, Steps=2734, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=359, Total reward=-1.0, Steps=2749, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=360, Total reward=0.7, Steps=2756, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=361, Total reward=-2.1, Steps=2772, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=362, Total reward=-0.9, Steps=2786, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=363, Total reward=0.4, Steps=2796, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=364, Total reward=-1.3, Steps=2814, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=365, Total reward=-1.3, Steps=2821, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=366, Total reward=-1.3, Steps=2828, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=367, Total reward=-1, Steps=2831, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=368, Total reward=-1, Steps=2834, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=369, Total reward=-1.3, Steps=2840, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=370, Total reward=-0.7, Steps=2852, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=371, Total reward=-2.0, Steps=2877, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=372, Total reward=-1.3, Steps=2883, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=373, Total reward=-1, Steps=2887, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=374, Total reward=-1.2, Steps=2892, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=375, Total reward=-1, Steps=2895, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=376, Total reward=-1.1, Steps=2899, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=377, Total reward=-1.2, Steps=2905, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=378, Total reward=-1.4, Steps=2912, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=379, Total reward=-0.3, Steps=2920, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=380, Total reward=-1, Steps=2923, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=381, Total reward=0.8, Steps=2929, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=382, Total reward=-1.5, Steps=2938, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=383, Total reward=-1.2, Steps=2944, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=384, Total reward=0.7, Steps=2951, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=385, Total reward=-0.5, Steps=2961, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=386, Total reward=-1.3, Steps=2979, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=387, Total reward=-1, Steps=2982, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=388, Total reward=-1.4, Steps=2990, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=389, Total reward=-1.3, Steps=2997, Training iteration=1\u001b[0m\n",
      "\u001b[34m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=389, Total reward=-1, Steps=3000, Training iteration=1\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=389, Total reward=-2.0, Steps=3000, Training iteration=1\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=389, Total reward=-2.0, Steps=3000, Training iteration=1\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=389, Total reward=-2.0, Steps=3000, Training iteration=1\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=389, Total reward=-2.0, Steps=3000, Training iteration=1\u001b[0m\n",
      "\u001b[34m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = -1.8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=390, Total reward=-1, Steps=3003, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=391, Total reward=-1.1, Steps=3007, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=392, Total reward=-1.1, Steps=3012, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=393, Total reward=-1, Steps=3015, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=394, Total reward=-2.1, Steps=3030, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=395, Total reward=-0.4, Steps=3039, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=396, Total reward=-1, Steps=3042, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=397, Total reward=-1.1, Steps=3046, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=398, Total reward=-1, Steps=3050, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=399, Total reward=-1.1, Steps=3054, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=400, Total reward=-1, Steps=3057, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=401, Total reward=-1.2, Steps=3063, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=402, Total reward=-1, Steps=3067, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=403, Total reward=-0.6, Steps=3078, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=404, Total reward=-0.6, Steps=3089, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=405, Total reward=-1, Steps=3092, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=406, Total reward=-0.4, Steps=3101, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=407, Total reward=0.3, Steps=3112, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=408, Total reward=-1, Steps=3115, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=409, Total reward=-0.9, Steps=3129, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=410, Total reward=-1.2, Steps=3134, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=411, Total reward=-1.1, Steps=3138, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=412, Total reward=-1.2, Steps=3144, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=413, Total reward=-1.1, Steps=3148, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=414, Total reward=-1, Steps=3151, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=415, Total reward=-2.2, Steps=3168, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=416, Total reward=-0.9, Steps=3182, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=417, Total reward=-1.1, Steps=3186, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=418, Total reward=-1.7, Steps=3197, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=419, Total reward=-1.0, Steps=3212, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=420, Total reward=-1.5, Steps=3220, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=421, Total reward=-1.4, Steps=3228, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=422, Total reward=-2.2, Steps=3245, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=423, Total reward=-0.2, Steps=3252, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=424, Total reward=-1.1, Steps=3256, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=425, Total reward=0.8, Steps=3262, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=426, Total reward=-1, Steps=3265, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=427, Total reward=-1.3, Steps=3272, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=428, Total reward=-1.2, Steps=3277, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=429, Total reward=0.6, Steps=3285, Training iteration=1\u001b[0m\n",
      "\u001b[34mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/2_Step-3288.ckpt.main_level.agent.main.online.onnx', '/opt/ml/output/data/checkpoint/2_Step-3288.ckpt.main_level.agent.main.online']\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=430, Total reward=-1.5, Steps=3294, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=431, Total reward=-1.1, Steps=3298, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=432, Total reward=-1, Steps=3302, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=433, Total reward=-1.2, Steps=3308, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=434, Total reward=-0.4, Steps=3317, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=435, Total reward=-0.7, Steps=3329, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=436, Total reward=-2.5, Steps=3349, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=437, Total reward=-1, Steps=3353, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=438, Total reward=-1.3, Steps=3359, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=439, Total reward=-1.1, Steps=3363, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=440, Total reward=-1, Steps=3367, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=441, Total reward=-1.3, Steps=3374, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=442, Total reward=-2.7, Steps=3396, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=443, Total reward=-1.3, Steps=3402, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=444, Total reward=-1, Steps=3405, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=445, Total reward=-0.5, Steps=3415, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=446, Total reward=-0.6, Steps=3426, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=447, Total reward=-1, Steps=3429, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=448, Total reward=-1, Steps=3433, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=449, Total reward=-1.4, Steps=3440, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=450, Total reward=0.9, Steps=3445, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=451, Total reward=1, Steps=3450, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=452, Total reward=1, Steps=3454, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=453, Total reward=-1.4, Steps=3462, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=454, Total reward=-1.1, Steps=3466, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=455, Total reward=-1.1, Steps=3470, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=456, Total reward=-1.1, Steps=3474, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=457, Total reward=-0.4, Steps=3483, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=458, Total reward=-1.3, Steps=3489, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=459, Total reward=-0.9, Steps=3503, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=460, Total reward=-1.2, Steps=3508, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=461, Total reward=-1.5, Steps=3516, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=462, Total reward=1, Steps=3520, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=463, Total reward=-1, Steps=3523, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=464, Total reward=-0.4, Steps=3532, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=465, Total reward=-2.1, Steps=3547, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=466, Total reward=-1.1, Steps=3551, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=467, Total reward=-1.1, Steps=3555, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=468, Total reward=-2.2, Steps=3572, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=469, Total reward=1, Steps=3576, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=470, Total reward=-0.8, Steps=3589, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=471, Total reward=-1.0, Steps=3604, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=472, Total reward=-0.6, Steps=3615, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=473, Total reward=0.7, Steps=3622, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=474, Total reward=-1.7, Steps=3633, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=475, Total reward=-1.3, Steps=3640, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=476, Total reward=-0.8, Steps=3653, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=477, Total reward=-1.4, Steps=3661, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=478, Total reward=-1, Steps=3664, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=479, Total reward=-1.1, Steps=3669, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=480, Total reward=-1.1, Steps=3674, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=481, Total reward=-1.1, Steps=3678, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=482, Total reward=-1, Steps=3682, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=483, Total reward=-1.1, Steps=3698, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=484, Total reward=-1, Steps=3702, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=485, Total reward=-1.1, Steps=3706, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=486, Total reward=-1.1, Steps=3710, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=487, Total reward=-2.3, Steps=3728, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=488, Total reward=0.6, Steps=3736, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=489, Total reward=-1.0, Steps=3751, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=490, Total reward=-1.1, Steps=3755, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=491, Total reward=-2.2, Steps=3772, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=492, Total reward=-1.1, Steps=3776, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=493, Total reward=0.7, Steps=3783, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=494, Total reward=-0.5, Steps=3793, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=495, Total reward=-1.1, Steps=3798, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=496, Total reward=-1, Steps=3801, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=497, Total reward=-2.0, Steps=3816, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=498, Total reward=-1.3, Steps=3822, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=499, Total reward=1, Steps=3826, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=500, Total reward=-1.2, Steps=3832, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=501, Total reward=-2.0, Steps=3847, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=502, Total reward=-0.1, Steps=3853, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=503, Total reward=-1, Steps=3856, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=504, Total reward=-1.2, Steps=3862, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=505, Total reward=-1, Steps=3865, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=506, Total reward=-1, Steps=3868, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=507, Total reward=-1, Steps=3871, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=508, Total reward=0.4, Steps=3881, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=509, Total reward=-1, Steps=3884, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=510, Total reward=-1, Steps=3888, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=511, Total reward=-0.5, Steps=3898, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=512, Total reward=-1.7, Steps=3909, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=513, Total reward=-0.2, Steps=3916, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=514, Total reward=-1.1, Steps=3920, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=515, Total reward=-1, Steps=3924, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=516, Total reward=-1.1, Steps=3928, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=517, Total reward=-1.1, Steps=3932, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=518, Total reward=-1.3, Steps=3939, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=519, Total reward=-1, Steps=3942, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=520, Total reward=-1, Steps=3945, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=521, Total reward=-1.3, Steps=3952, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=522, Total reward=-1.2, Steps=3958, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=523, Total reward=-0.4, Steps=3967, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=524, Total reward=-1.2, Steps=3972, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=525, Total reward=-1.5, Steps=3981, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=526, Total reward=-1, Steps=3984, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=527, Total reward=-2.1, Steps=4000, Training iteration=1\u001b[0m\n",
      "\u001b[34m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=527, Total reward=-2.0, Steps=4000, Training iteration=1\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=527, Total reward=-2.0, Steps=4000, Training iteration=1\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=527, Total reward=-2.0, Steps=4000, Training iteration=1\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=527, Total reward=-2.0, Steps=4000, Training iteration=1\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=527, Total reward=-2.0, Steps=4000, Training iteration=1\u001b[0m\n",
      "\u001b[34m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = -2.0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=528, Total reward=-1.4, Steps=4008, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=529, Total reward=-1.1, Steps=4024, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=530, Total reward=-1, Steps=4027, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=531, Total reward=-2.4, Steps=4046, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=532, Total reward=-2.3, Steps=4064, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=533, Total reward=-1.3, Steps=4082, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=534, Total reward=-2.2, Steps=4099, Training iteration=1\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=535, Total reward=-1.3, Steps=4105, Training iteration=1\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=0.0030472620856016874, KL divergence=[0.], Entropy=[-0.02166012], training epoch=0, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.02294323220849037, KL divergence=[0.], Entropy=[-0.02167687], training epoch=1, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.036065809428691864, KL divergence=[0.], Entropy=[-0.021619], training epoch=2, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.034248486161231995, KL divergence=[0.], Entropy=[-0.02155224], training epoch=3, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.03688715398311615, KL divergence=[0.], Entropy=[-0.02152472], training epoch=4, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.03771303966641426, KL divergence=[0.], Entropy=[-0.02151678], training epoch=5, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.05530231073498726, KL divergence=[0.], Entropy=[-0.0215214], training epoch=6, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.05024867504835129, KL divergence=[0.], Entropy=[-0.02146888], training epoch=7, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.04377351328730583, KL divergence=[0.], Entropy=[-0.02142153], training epoch=8, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.06497664749622345, KL divergence=[0.], Entropy=[-0.02145761], training epoch=9, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/3_Step-4105.ckpt.main_level.agent.main.online.onnx', '/opt/ml/output/data/checkpoint/3_Step-4105.ckpt.main_level.agent.main.online']\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=536, Total reward=-1, Steps=4108, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=537, Total reward=0.3, Steps=4120, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=538, Total reward=-1.1, Steps=4124, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=539, Total reward=-1.0, Steps=4139, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=540, Total reward=-1, Steps=4143, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=541, Total reward=0.8, Steps=4149, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=542, Total reward=1, Steps=4153, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=543, Total reward=-1, Steps=4156, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=544, Total reward=-0.1, Steps=4162, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=545, Total reward=0.9, Steps=4166, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=546, Total reward=-0.1, Steps=4172, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=547, Total reward=-0.7, Steps=4184, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=548, Total reward=-0.3, Steps=4192, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=549, Total reward=-2.1, Steps=4208, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=550, Total reward=-1.4, Steps=4216, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=551, Total reward=-2.4, Steps=4235, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=552, Total reward=-1, Steps=4239, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=553, Total reward=-2.4, Steps=4258, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=554, Total reward=0.8, Steps=4265, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=555, Total reward=-1.2, Steps=4270, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=556, Total reward=-1.4, Steps=4277, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=557, Total reward=0.1, Steps=4291, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=558, Total reward=-1.1, Steps=4296, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=559, Total reward=-1.2, Steps=4301, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=560, Total reward=-1.1, Steps=4305, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=561, Total reward=-1.0, Steps=4320, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=562, Total reward=-1, Steps=4323, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=563, Total reward=-0.7, Steps=4335, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=564, Total reward=-1.2, Steps=4341, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=565, Total reward=-1.1, Steps=4346, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=566, Total reward=-1.3, Steps=4352, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=567, Total reward=-1, Steps=4355, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=568, Total reward=1, Steps=4358, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=569, Total reward=-1.4, Steps=4366, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=570, Total reward=-1.1, Steps=4382, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=571, Total reward=-2.3, Steps=4400, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=572, Total reward=-1.2, Steps=4406, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=573, Total reward=-1, Steps=4409, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=574, Total reward=0.9, Steps=4414, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=575, Total reward=-1.2, Steps=4420, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=576, Total reward=-1.2, Steps=4425, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=577, Total reward=-0.7, Steps=4437, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=578, Total reward=-0.2, Steps=4444, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=579, Total reward=-1.2, Steps=4449, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=580, Total reward=-1.4, Steps=4457, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=581, Total reward=-1, Steps=4460, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=582, Total reward=-1.1, Steps=4464, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=583, Total reward=-0.4, Steps=4473, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=584, Total reward=0.9, Steps=4477, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=585, Total reward=-2.3, Steps=4495, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=586, Total reward=-1.5, Steps=4504, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=587, Total reward=-1, Steps=4507, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=588, Total reward=-1.1, Steps=4511, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=589, Total reward=-1.3, Steps=4517, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=590, Total reward=-1.2, Steps=4522, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=591, Total reward=1, Steps=4525, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=592, Total reward=-0.2, Steps=4532, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=593, Total reward=-1.1, Steps=4536, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=594, Total reward=1, Steps=4540, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=595, Total reward=-1.3, Steps=4547, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=596, Total reward=-2.0, Steps=4562, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=597, Total reward=-1.3, Steps=4569, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=598, Total reward=-0.9, Steps=4583, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=599, Total reward=-0.6, Steps=4594, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=600, Total reward=-0.4, Steps=4603, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=601, Total reward=-0.4, Steps=4612, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=602, Total reward=0.9, Steps=4616, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=603, Total reward=-1.6, Steps=4637, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=604, Total reward=-2.1, Steps=4653, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=605, Total reward=-1, Steps=4656, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=606, Total reward=-1, Steps=4659, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=607, Total reward=-1.1, Steps=4663, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=608, Total reward=-1, Steps=4666, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=609, Total reward=-1.2, Steps=4671, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=610, Total reward=-1.2, Steps=4688, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=611, Total reward=-1, Steps=4691, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=612, Total reward=-1, Steps=4694, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=613, Total reward=0.7, Steps=4700, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=614, Total reward=-1.1, Steps=4704, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=615, Total reward=-1, Steps=4707, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=616, Total reward=-1.1, Steps=4711, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=617, Total reward=1, Steps=4715, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=618, Total reward=-1.1, Steps=4720, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=619, Total reward=-1, Steps=4723, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=620, Total reward=-0.6, Steps=4734, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=621, Total reward=-1.1, Steps=4738, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=622, Total reward=0.8, Steps=4744, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=623, Total reward=-1.1, Steps=4748, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=624, Total reward=-1, Steps=4751, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=625, Total reward=-1.1, Steps=4755, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=626, Total reward=-1.3, Steps=4762, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=627, Total reward=-1.6, Steps=4783, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=628, Total reward=-0.5, Steps=4793, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=629, Total reward=-1.1, Steps=4797, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=630, Total reward=-1, Steps=4800, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=631, Total reward=-1.1, Steps=4805, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=632, Total reward=-2.3, Steps=4823, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=633, Total reward=-1.3, Steps=4829, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=634, Total reward=-1.1, Steps=4833, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=635, Total reward=-1, Steps=4836, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=636, Total reward=0.7, Steps=4842, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=637, Total reward=-1, Steps=4845, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=638, Total reward=-2.3, Steps=4863, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=639, Total reward=-1.2, Steps=4868, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=640, Total reward=-1.6, Steps=4878, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=641, Total reward=-1.5, Steps=4887, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=642, Total reward=-1.3, Steps=4894, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=643, Total reward=-1, Steps=4897, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=644, Total reward=-2.2, Steps=4914, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=645, Total reward=-1.4, Steps=4922, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=646, Total reward=0.7, Steps=4929, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=647, Total reward=-1.1, Steps=4933, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=648, Total reward=-1, Steps=4936, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=649, Total reward=-1, Steps=4939, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=650, Total reward=-0.3, Steps=4947, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=651, Total reward=-1.1, Steps=4951, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=652, Total reward=-1.1, Steps=4955, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=653, Total reward=-1, Steps=4958, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=654, Total reward=-0.5, Steps=4968, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=655, Total reward=-1.1, Steps=4972, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=656, Total reward=-2.4, Steps=4991, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=657, Total reward=-1, Steps=4994, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=658, Total reward=-1, Steps=4998, Training iteration=2\u001b[0m\n",
      "\u001b[34m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=658, Total reward=-2.0, Steps=5000, Training iteration=2\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=658, Total reward=-2.0, Steps=5000, Training iteration=2\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=658, Total reward=-2.0, Steps=5000, Training iteration=2\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=658, Total reward=-2.0, Steps=5000, Training iteration=2\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=658, Total reward=1, Steps=5000, Training iteration=2\u001b[0m\n",
      "\u001b[34m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = -1.4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=659, Total reward=-0.3, Steps=5008, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=660, Total reward=-1.1, Steps=5013, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=661, Total reward=0.3, Steps=5025, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=662, Total reward=-2.4, Steps=5044, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=663, Total reward=-1.1, Steps=5048, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=664, Total reward=1, Steps=5052, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=665, Total reward=-1.1, Steps=5056, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=666, Total reward=-1, Steps=5060, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=667, Total reward=-1.1, Steps=5064, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=668, Total reward=-1, Steps=5068, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=669, Total reward=-1, Steps=5072, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=670, Total reward=1, Steps=5076, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=671, Total reward=-1.1, Steps=5080, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=672, Total reward=1, Steps=5083, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=673, Total reward=0.3, Steps=5095, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=674, Total reward=-0.7, Steps=5107, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=675, Total reward=-1.5, Steps=5115, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=676, Total reward=-1.1, Steps=5120, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=677, Total reward=-1.5, Steps=5129, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=678, Total reward=-1.2, Steps=5134, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=679, Total reward=-2.3, Steps=5152, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=680, Total reward=-0.6, Steps=5163, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=681, Total reward=-0.1, Steps=5169, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=682, Total reward=-1.1, Steps=5174, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=683, Total reward=-1, Steps=5177, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=684, Total reward=-1.3, Steps=5184, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=685, Total reward=-1.8, Steps=5196, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=686, Total reward=-1, Steps=5199, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=687, Total reward=-1.7, Steps=5210, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=688, Total reward=-1.1, Steps=5214, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=689, Total reward=-1.4, Steps=5222, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=690, Total reward=-1.1, Steps=5227, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=691, Total reward=0.9, Steps=5232, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=692, Total reward=-0.6, Steps=5243, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=693, Total reward=-1, Steps=5246, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=694, Total reward=-1, Steps=5249, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=695, Total reward=-1.1, Steps=5265, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=696, Total reward=-0.9, Steps=5279, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=697, Total reward=-1.1, Steps=5283, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=698, Total reward=-1.1, Steps=5287, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=699, Total reward=-0.2, Steps=5294, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=700, Total reward=1, Steps=5298, Training iteration=2\u001b[0m\n",
      "\u001b[34mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/4_Step-5299.ckpt.main_level.agent.main.online.onnx', '/opt/ml/output/data/checkpoint/4_Step-5299.ckpt.main_level.agent.main.online']\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=701, Total reward=-1.1, Steps=5302, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=702, Total reward=-1.3, Steps=5308, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=703, Total reward=-1, Steps=5311, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=704, Total reward=-1.1, Steps=5315, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=705, Total reward=-1.2, Steps=5321, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=706, Total reward=0.8, Steps=5327, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=707, Total reward=-1.2, Steps=5333, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=708, Total reward=-2.2, Steps=5350, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=709, Total reward=-1.1, Steps=5355, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=710, Total reward=-0.6, Steps=5366, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=711, Total reward=-1.1, Steps=5370, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=712, Total reward=-2.1, Steps=5386, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=713, Total reward=-1, Steps=5389, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=714, Total reward=-1.2, Steps=5394, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=715, Total reward=-0.7, Steps=5406, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=716, Total reward=-1, Steps=5409, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=717, Total reward=-1.1, Steps=5414, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=718, Total reward=-1, Steps=5417, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=719, Total reward=0.3, Steps=5429, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=720, Total reward=-1.3, Steps=5435, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=721, Total reward=-2.8, Steps=5458, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=722, Total reward=-1.2, Steps=5464, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=723, Total reward=-2.4, Steps=5483, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=724, Total reward=-1, Steps=5486, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=725, Total reward=-1, Steps=5489, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=726, Total reward=-0.9, Steps=5503, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=727, Total reward=-1.2, Steps=5508, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=728, Total reward=-1.8, Steps=5531, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=729, Total reward=-1.4, Steps=5538, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=730, Total reward=-1.1, Steps=5542, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=731, Total reward=-1.0, Steps=5557, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=732, Total reward=-0.7, Steps=5569, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=733, Total reward=1, Steps=5573, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=734, Total reward=0.6, Steps=5580, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=735, Total reward=-1, Steps=5583, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=736, Total reward=-1.2, Steps=5589, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=737, Total reward=-2.1, Steps=5604, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=738, Total reward=-0.4, Steps=5623, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=739, Total reward=-1.2, Steps=5629, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=740, Total reward=-0.6, Steps=5640, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=741, Total reward=-0.6, Steps=5651, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=742, Total reward=-1.4, Steps=5659, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=743, Total reward=-1, Steps=5662, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=744, Total reward=-1.1, Steps=5667, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=745, Total reward=-1.2, Steps=5672, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=746, Total reward=-2.0, Steps=5687, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=747, Total reward=-1.1, Steps=5691, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=748, Total reward=-1.3, Steps=5697, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=749, Total reward=-1, Steps=5700, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=750, Total reward=-1.4, Steps=5719, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=751, Total reward=-1.2, Steps=5736, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=752, Total reward=-1, Steps=5739, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=753, Total reward=-1, Steps=5742, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=754, Total reward=0.9, Steps=5747, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=755, Total reward=-0.4, Steps=5756, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=756, Total reward=0.3, Steps=5767, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=757, Total reward=-1.2, Steps=5772, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=758, Total reward=0.0, Steps=5787, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=759, Total reward=-1.2, Steps=5793, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=760, Total reward=-1.1, Steps=5797, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=761, Total reward=0.3, Steps=5809, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=762, Total reward=-1.2, Steps=5814, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=763, Total reward=-1, Steps=5817, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=764, Total reward=0.8, Steps=5823, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=765, Total reward=-1.1, Steps=5827, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=766, Total reward=-1.1, Steps=5832, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=767, Total reward=-0.9, Steps=5846, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=768, Total reward=-1.2, Steps=5851, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=769, Total reward=-1, Steps=5854, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=770, Total reward=-2.7, Steps=5876, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=771, Total reward=-0.9, Steps=5890, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=772, Total reward=0.9, Steps=5895, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=773, Total reward=-2.6, Steps=5916, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=774, Total reward=-1, Steps=5919, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=775, Total reward=-0.9, Steps=5933, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=776, Total reward=-1.2, Steps=5939, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=777, Total reward=-1.5, Steps=5948, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=778, Total reward=-1, Steps=5951, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=779, Total reward=-1.2, Steps=5956, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=780, Total reward=-1, Steps=5959, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=781, Total reward=-1.3, Steps=5965, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=782, Total reward=0.2, Steps=5978, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=783, Total reward=-1, Steps=5981, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=784, Total reward=-0.9, Steps=5995, Training iteration=2\u001b[0m\n",
      "\u001b[34m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=784, Total reward=-2.0, Steps=6000, Training iteration=2\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=784, Total reward=-2.0, Steps=6000, Training iteration=2\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=784, Total reward=-2.0, Steps=6000, Training iteration=2\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=784, Total reward=-2.0, Steps=6000, Training iteration=2\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=784, Total reward=-2.0, Steps=6000, Training iteration=2\u001b[0m\n",
      "\u001b[34m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = -2.0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=785, Total reward=-0.9, Steps=6014, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=786, Total reward=-0.2, Steps=6021, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=787, Total reward=-1.7, Steps=6031, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=788, Total reward=-1.2, Steps=6036, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=789, Total reward=-0.8, Steps=6049, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=790, Total reward=0.6, Steps=6058, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=791, Total reward=-1, Steps=6061, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=792, Total reward=0.0, Steps=6076, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=793, Total reward=-2.1, Steps=6092, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=794, Total reward=-1.5, Steps=6101, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=795, Total reward=-1, Steps=6104, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=796, Total reward=-1.3, Steps=6110, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=797, Total reward=-1, Steps=6114, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=798, Total reward=-1.1, Steps=6130, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=799, Total reward=-1, Steps=6134, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=800, Total reward=-1.1, Steps=6138, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=801, Total reward=-1.3, Steps=6144, Training iteration=2\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=802, Total reward=-0.7, Steps=6156, Training iteration=2\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=0.009363674558699131, KL divergence=[0.], Entropy=[-0.02130744], training epoch=0, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.01998184435069561, KL divergence=[0.], Entropy=[-0.0213548], training epoch=1, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.02685781568288803, KL divergence=[0.], Entropy=[-0.02132719], training epoch=2, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.039357952773571014, KL divergence=[0.], Entropy=[-0.02124468], training epoch=3, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.04640350118279457, KL divergence=[0.], Entropy=[-0.02126881], training epoch=4, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.043893035501241684, KL divergence=[0.], Entropy=[-0.02124107], training epoch=5, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.05287407338619232, KL divergence=[0.], Entropy=[-0.02119255], training epoch=6, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.06428222358226776, KL divergence=[0.], Entropy=[-0.02116178], training epoch=7, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.059598058462142944, KL divergence=[0.], Entropy=[-0.02117979], training epoch=8, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.072533518075943, KL divergence=[0.], Entropy=[-0.02114712], training epoch=9, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/5_Step-6156.ckpt.main_level.agent.main.online.onnx', '/opt/ml/output/data/checkpoint/5_Step-6156.ckpt.main_level.agent.main.online']\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=803, Total reward=-1, Steps=6160, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=804, Total reward=-1.1, Steps=6164, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=805, Total reward=-1.1, Steps=6168, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=806, Total reward=-1, Steps=6171, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=807, Total reward=-1.2, Steps=6188, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=808, Total reward=-0.3, Steps=6196, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=809, Total reward=-0.5, Steps=6206, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=810, Total reward=-1.3, Steps=6212, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=811, Total reward=-1, Steps=6215, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=812, Total reward=-1.2, Steps=6221, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=813, Total reward=-1.3, Steps=6228, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=814, Total reward=-1, Steps=6231, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=815, Total reward=-1.3, Steps=6249, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=816, Total reward=-0.4, Steps=6258, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=817, Total reward=-0.6, Steps=6269, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=818, Total reward=-1.3, Steps=6276, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=819, Total reward=-1, Steps=6279, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=820, Total reward=-1, Steps=6282, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=821, Total reward=0.3, Steps=6293, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=822, Total reward=-1.1, Steps=6297, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=823, Total reward=-1, Steps=6300, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=824, Total reward=-1.1, Steps=6304, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=825, Total reward=0.4, Steps=6315, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=826, Total reward=-1.1, Steps=6320, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=827, Total reward=-1.6, Steps=6330, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=828, Total reward=-1.2, Steps=6336, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=829, Total reward=0.9, Steps=6341, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=830, Total reward=1, Steps=6345, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=831, Total reward=-0.4, Steps=6354, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=832, Total reward=0.8, Steps=6360, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=833, Total reward=-1, Steps=6364, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=834, Total reward=-1.1, Steps=6368, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=835, Total reward=-1, Steps=6372, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=836, Total reward=-1.3, Steps=6378, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=837, Total reward=-1.1, Steps=6383, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=838, Total reward=-1.1, Steps=6388, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=839, Total reward=-2.3, Steps=6406, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=840, Total reward=-1, Steps=6409, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=841, Total reward=-1, Steps=6412, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=842, Total reward=0.5, Steps=6422, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=843, Total reward=0.7, Steps=6429, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=844, Total reward=-0.9, Steps=6443, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=845, Total reward=1, Steps=6446, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=846, Total reward=-1, Steps=6449, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=847, Total reward=-1, Steps=6453, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=848, Total reward=-1, Steps=6457, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=849, Total reward=-1, Steps=6460, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=850, Total reward=-2.0, Steps=6475, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=851, Total reward=-1.3, Steps=6482, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=852, Total reward=-1, Steps=6485, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=853, Total reward=-1.3, Steps=6491, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=854, Total reward=-1.3, Steps=6498, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=855, Total reward=0.6, Steps=6506, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=856, Total reward=-0.3, Steps=6514, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=857, Total reward=0.9, Steps=6519, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=858, Total reward=-1, Steps=6522, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=859, Total reward=-1.1, Steps=6526, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=860, Total reward=-1, Steps=6529, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=861, Total reward=-1.1, Steps=6533, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=862, Total reward=0.5, Steps=6542, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=863, Total reward=-1.5, Steps=6550, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=864, Total reward=-1, Steps=6554, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=865, Total reward=-2.1, Steps=6570, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=866, Total reward=-1, Steps=6573, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=867, Total reward=-1.1, Steps=6577, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=868, Total reward=-1.1, Steps=6581, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=869, Total reward=0.8, Steps=6587, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=870, Total reward=0.9, Steps=6592, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=871, Total reward=-2.1, Steps=6608, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=872, Total reward=-1, Steps=6611, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=873, Total reward=-1, Steps=6614, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=874, Total reward=-0.3, Steps=6622, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=875, Total reward=-0.4, Steps=6631, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=876, Total reward=-1, Steps=6635, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=877, Total reward=-0.9, Steps=6649, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=878, Total reward=-0.4, Steps=6658, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=879, Total reward=-1, Steps=6661, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=880, Total reward=-1, Steps=6664, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=881, Total reward=0.8, Steps=6670, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=882, Total reward=-1.2, Steps=6676, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=883, Total reward=-2.2, Steps=6693, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=884, Total reward=-1.7, Steps=6704, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=885, Total reward=-1, Steps=6707, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=886, Total reward=-1.6, Steps=6716, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=887, Total reward=-0.4, Steps=6725, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=888, Total reward=-1.4, Steps=6732, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=889, Total reward=-0.3, Steps=6740, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=890, Total reward=-1.1, Steps=6745, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=891, Total reward=-1.3, Steps=6751, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=892, Total reward=-1.3, Steps=6757, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=893, Total reward=-1.4, Steps=6765, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=894, Total reward=-0.9, Steps=6779, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=895, Total reward=-1.2, Steps=6784, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=896, Total reward=-0.6, Steps=6795, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=897, Total reward=-0.7, Steps=6807, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=898, Total reward=-0.5, Steps=6817, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=899, Total reward=-1, Steps=6820, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=900, Total reward=-0.9, Steps=6834, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=901, Total reward=-2.0, Steps=6848, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=902, Total reward=-2.0, Steps=6863, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=903, Total reward=-1, Steps=6867, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=904, Total reward=-0.4, Steps=6876, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=905, Total reward=-0.7, Steps=6888, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=906, Total reward=-1, Steps=6891, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=907, Total reward=0.9, Steps=6896, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=908, Total reward=-2.3, Steps=6914, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=909, Total reward=-0.1, Steps=6920, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=910, Total reward=0.7, Steps=6927, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=911, Total reward=-1, Steps=6930, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=912, Total reward=-1, Steps=6933, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=913, Total reward=-1.2, Steps=6939, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=914, Total reward=0.7, Steps=6946, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=915, Total reward=-1.9, Steps=6959, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=916, Total reward=-1.3, Steps=6966, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=917, Total reward=-1, Steps=6970, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=918, Total reward=-0.8, Steps=6983, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=919, Total reward=-1, Steps=6986, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=920, Total reward=-1, Steps=6989, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=921, Total reward=-1.1, Steps=6993, Training iteration=3\u001b[0m\n",
      "\u001b[34m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=921, Total reward=-2.0, Steps=7000, Training iteration=3\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=921, Total reward=-2.0, Steps=7000, Training iteration=3\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=921, Total reward=-2.0, Steps=7000, Training iteration=3\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=921, Total reward=-2.0, Steps=7000, Training iteration=3\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=921, Total reward=-2.0, Steps=7000, Training iteration=3\u001b[0m\n",
      "\u001b[34m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = -2.0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=922, Total reward=-1.1, Steps=7016, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=923, Total reward=-1.1, Steps=7020, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=924, Total reward=-0.8, Steps=7033, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=925, Total reward=-1.2, Steps=7050, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=926, Total reward=-1, Steps=7053, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=927, Total reward=-0.1, Steps=7059, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=928, Total reward=-1.3, Steps=7065, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=929, Total reward=0.8, Steps=7071, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=930, Total reward=-1, Steps=7074, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=931, Total reward=-1.5, Steps=7083, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=932, Total reward=-1, Steps=7086, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=933, Total reward=-1.4, Steps=7094, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=934, Total reward=-1.1, Steps=7098, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=935, Total reward=-0.8, Steps=7111, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=936, Total reward=-1, Steps=7114, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=937, Total reward=-1, Steps=7117, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=938, Total reward=-1.1, Steps=7122, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=939, Total reward=-2.5, Steps=7142, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=940, Total reward=-1, Steps=7145, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=941, Total reward=0.7, Steps=7152, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=942, Total reward=-1.1, Steps=7156, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=943, Total reward=1, Steps=7159, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=944, Total reward=-1, Steps=7162, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=945, Total reward=-1.1, Steps=7167, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=946, Total reward=-1, Steps=7171, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=947, Total reward=-1.4, Steps=7178, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=948, Total reward=-1.3, Steps=7184, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=949, Total reward=-0.8, Steps=7197, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=950, Total reward=-0.3, Steps=7205, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=951, Total reward=-1.2, Steps=7222, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=952, Total reward=-2.5, Steps=7242, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=953, Total reward=0.8, Steps=7249, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=954, Total reward=-1.2, Steps=7255, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=955, Total reward=-1, Steps=7258, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=956, Total reward=-1.1, Steps=7262, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=957, Total reward=-0.2, Steps=7269, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=958, Total reward=-1, Steps=7272, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=959, Total reward=-1.1, Steps=7276, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=960, Total reward=-1.5, Steps=7285, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=961, Total reward=-1.1, Steps=7290, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=962, Total reward=-1.2, Steps=7295, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=963, Total reward=0.9, Steps=7300, Training iteration=3\u001b[0m\n",
      "\u001b[34mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/6_Step-7302.ckpt.main_level.agent.main.online.onnx', '/opt/ml/output/data/checkpoint/6_Step-7302.ckpt.main_level.agent.main.online']\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=964, Total reward=-0.9, Steps=7314, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=965, Total reward=-1, Steps=7317, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=966, Total reward=1, Steps=7321, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=967, Total reward=-2.4, Steps=7340, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=968, Total reward=-1.4, Steps=7347, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=969, Total reward=-1, Steps=7351, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=970, Total reward=-0.6, Steps=7372, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=971, Total reward=0.5, Steps=7381, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=972, Total reward=-1.4, Steps=7388, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=973, Total reward=-1, Steps=7391, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=974, Total reward=-1.4, Steps=7398, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=975, Total reward=-0.2, Steps=7405, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=976, Total reward=-1.1, Steps=7409, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=977, Total reward=-1.3, Steps=7416, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=978, Total reward=-1.2, Steps=7433, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=979, Total reward=-1.1, Steps=7437, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=980, Total reward=-1.2, Steps=7442, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=981, Total reward=-0.3, Steps=7450, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=982, Total reward=0, Steps=7455, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=983, Total reward=-0.1, Steps=7461, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=984, Total reward=-1.1, Steps=7466, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=985, Total reward=-1.7, Steps=7477, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=986, Total reward=-0.2, Steps=7484, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=987, Total reward=-1, Steps=7487, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=988, Total reward=-1.1, Steps=7491, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=989, Total reward=-2.1, Steps=7507, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=990, Total reward=-0.3, Steps=7515, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=991, Total reward=-1.1, Steps=7519, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=992, Total reward=-1, Steps=7522, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=993, Total reward=-1, Steps=7525, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=994, Total reward=-1, Steps=7528, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=995, Total reward=-0.2, Steps=7535, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=996, Total reward=-1, Steps=7538, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=997, Total reward=-1.1, Steps=7543, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=998, Total reward=-1.1, Steps=7547, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=999, Total reward=-3.6, Steps=7578, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1000, Total reward=-0.5, Steps=7588, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1001, Total reward=-0.1, Steps=7594, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1002, Total reward=-0.6, Steps=7605, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1003, Total reward=-1.0, Steps=7620, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1004, Total reward=-0.6, Steps=7631, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1005, Total reward=-1, Steps=7634, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1006, Total reward=-0.1, Steps=7640, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1007, Total reward=0.9, Steps=7645, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1008, Total reward=-0.3, Steps=7653, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1009, Total reward=-1.1, Steps=7658, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1010, Total reward=-1.3, Steps=7665, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1011, Total reward=-1.4, Steps=7672, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1012, Total reward=0.9, Steps=7677, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1013, Total reward=-1.3, Steps=7695, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1014, Total reward=-0.6, Steps=7706, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1015, Total reward=0.7, Steps=7713, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1016, Total reward=-1, Steps=7716, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1017, Total reward=-1, Steps=7719, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1018, Total reward=-0.4, Steps=7728, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1019, Total reward=-0.9, Steps=7742, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1020, Total reward=-1, Steps=7746, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1021, Total reward=0.3, Steps=7757, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1022, Total reward=-1, Steps=7760, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1023, Total reward=-1, Steps=7764, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1024, Total reward=-1.8, Steps=7776, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1025, Total reward=1, Steps=7780, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1026, Total reward=-0.1, Steps=7786, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1027, Total reward=-1.1, Steps=7791, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1028, Total reward=0.8, Steps=7797, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1029, Total reward=-1, Steps=7800, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1030, Total reward=1, Steps=7805, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1031, Total reward=-1.1, Steps=7821, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1032, Total reward=-1.3, Steps=7828, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1033, Total reward=-0.3, Steps=7836, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1034, Total reward=-0.8, Steps=7849, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1035, Total reward=-2.4, Steps=7868, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1036, Total reward=0.2, Steps=7880, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1037, Total reward=-1, Steps=7883, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1038, Total reward=0.7, Steps=7891, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1039, Total reward=-0.9, Steps=7905, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1040, Total reward=-1, Steps=7908, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1041, Total reward=-1.2, Steps=7913, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1042, Total reward=1, Steps=7917, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1043, Total reward=-1, Steps=7920, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1044, Total reward=-1, Steps=7923, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1045, Total reward=-1, Steps=7927, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1046, Total reward=-2.3, Steps=7945, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1047, Total reward=-1.1, Steps=7950, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1048, Total reward=-1, Steps=7953, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1049, Total reward=-2.1, Steps=7969, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1050, Total reward=-1.1, Steps=7973, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1051, Total reward=-1.3, Steps=7980, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1052, Total reward=-1.1, Steps=7984, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1053, Total reward=-1, Steps=7987, Training iteration=3\u001b[0m\n",
      "\u001b[34m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=1053, Total reward=-2.0, Steps=8000, Training iteration=3\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=1053, Total reward=-2.0, Steps=8000, Training iteration=3\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=1053, Total reward=-2.0, Steps=8000, Training iteration=3\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=1053, Total reward=-2.0, Steps=8000, Training iteration=3\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=1053, Total reward=-2.0, Steps=8000, Training iteration=3\u001b[0m\n",
      "\u001b[34m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = -2.0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1054, Total reward=-1.1, Steps=8004, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1055, Total reward=-1, Steps=8007, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1056, Total reward=-1.9, Steps=8031, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1057, Total reward=-1, Steps=8034, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1058, Total reward=-1.1, Steps=8038, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1059, Total reward=-1.2, Steps=8043, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1060, Total reward=-2.2, Steps=8060, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1061, Total reward=-1, Steps=8063, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1062, Total reward=-1, Steps=8067, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1063, Total reward=-1.2, Steps=8073, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1064, Total reward=-1.2, Steps=8079, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1065, Total reward=-1.3, Steps=8097, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1066, Total reward=-0.5, Steps=8107, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1067, Total reward=0.8, Steps=8113, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1068, Total reward=-1.2, Steps=8119, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1069, Total reward=-2.4, Steps=8138, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1070, Total reward=0.7, Steps=8145, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1071, Total reward=0.7, Steps=8153, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1072, Total reward=-1.4, Steps=8160, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1073, Total reward=-1.1, Steps=8164, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1074, Total reward=-1, Steps=8167, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1075, Total reward=-1.0, Steps=8182, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1076, Total reward=-1, Steps=8185, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1077, Total reward=-1.3, Steps=8192, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1078, Total reward=1, Steps=8196, Training iteration=3\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1079, Total reward=-0.7, Steps=8208, Training iteration=3\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=0.003760245628654957, KL divergence=[0.], Entropy=[-0.02111457], training epoch=0, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.024332869797945023, KL divergence=[0.], Entropy=[-0.02098321], training epoch=1, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.04418126121163368, KL divergence=[0.], Entropy=[-0.02096626], training epoch=2, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.052966270595788956, KL divergence=[0.], Entropy=[-0.02087491], training epoch=3, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.06901174783706665, KL divergence=[0.], Entropy=[-0.02083186], training epoch=4, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.06656533479690552, KL divergence=[0.], Entropy=[-0.02075891], training epoch=5, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.07660737633705139, KL divergence=[0.], Entropy=[-0.02069473], training epoch=6, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.07932116836309433, KL divergence=[0.], Entropy=[-0.02066231], training epoch=7, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.07952086627483368, KL divergence=[0.], Entropy=[-0.02063369], training epoch=8, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.08379003405570984, KL divergence=[0.], Entropy=[-0.02052104], training epoch=9, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/7_Step-8208.ckpt.main_level.agent.main.online.onnx', '/opt/ml/output/data/checkpoint/7_Step-8208.ckpt.main_level.agent.main.online']\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1080, Total reward=-0.1, Steps=8214, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1081, Total reward=-1, Steps=8218, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1082, Total reward=-1.2, Steps=8224, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1083, Total reward=-1, Steps=8227, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1084, Total reward=-1, Steps=8230, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1085, Total reward=-2.7, Steps=8252, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1086, Total reward=-1, Steps=8255, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1087, Total reward=-1.1, Steps=8260, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1088, Total reward=-1.2, Steps=8265, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1089, Total reward=-1, Steps=8268, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1090, Total reward=-0.5, Steps=8278, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1091, Total reward=-1, Steps=8282, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1092, Total reward=-1.5, Steps=8290, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1093, Total reward=1, Steps=8293, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1094, Total reward=-0.5, Steps=8303, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1095, Total reward=-1, Steps=8307, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1096, Total reward=0.3, Steps=8318, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1097, Total reward=-2.0, Steps=8332, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1098, Total reward=-1, Steps=8335, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1099, Total reward=-2.4, Steps=8353, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1100, Total reward=-1, Steps=8357, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1101, Total reward=-1, Steps=8361, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1102, Total reward=-1.2, Steps=8366, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1103, Total reward=-1.0, Steps=8381, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1104, Total reward=1, Steps=8385, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1105, Total reward=-1, Steps=8389, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1106, Total reward=-1.1, Steps=8393, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1107, Total reward=-0.1, Steps=8399, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1108, Total reward=-1, Steps=8402, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1109, Total reward=-1.3, Steps=8408, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1110, Total reward=-1.3, Steps=8415, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1111, Total reward=-0.9, Steps=8429, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1112, Total reward=-0.2, Steps=8436, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1113, Total reward=-1, Steps=8439, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1114, Total reward=-2.4, Steps=8458, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1115, Total reward=-1, Steps=8461, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1116, Total reward=0.8, Steps=8467, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1117, Total reward=-1.4, Steps=8475, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1118, Total reward=-1, Steps=8478, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1119, Total reward=0.9, Steps=8483, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1120, Total reward=0.9, Steps=8488, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1121, Total reward=-1.1, Steps=8492, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1122, Total reward=-2.0, Steps=8507, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1123, Total reward=-2.1, Steps=8523, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1124, Total reward=-1, Steps=8526, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1125, Total reward=-0.4, Steps=8535, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1126, Total reward=-1, Steps=8538, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1127, Total reward=-0.7, Steps=8550, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1128, Total reward=0.7, Steps=8557, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1129, Total reward=-0.2, Steps=8564, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1130, Total reward=-1.1, Steps=8568, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1131, Total reward=0.8, Steps=8574, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1132, Total reward=-1.1, Steps=8579, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1133, Total reward=0.7, Steps=8586, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1134, Total reward=-1.1, Steps=8590, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1135, Total reward=-1.1, Steps=8594, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1136, Total reward=-1.1, Steps=8598, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1137, Total reward=0.7, Steps=8604, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1138, Total reward=-1, Steps=8607, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1139, Total reward=-1.4, Steps=8615, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1140, Total reward=-1, Steps=8618, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1141, Total reward=-1.2, Steps=8623, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1142, Total reward=-1, Steps=8626, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1143, Total reward=-1, Steps=8629, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1144, Total reward=-0.7, Steps=8641, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1145, Total reward=0.8, Steps=8647, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1146, Total reward=-0.6, Steps=8658, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1147, Total reward=-1.4, Steps=8666, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1148, Total reward=-1, Steps=8669, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1149, Total reward=0.5, Steps=8678, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1150, Total reward=-1, Steps=8681, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1151, Total reward=-0.3, Steps=8689, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1152, Total reward=-1.2, Steps=8694, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1153, Total reward=0.6, Steps=8702, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1154, Total reward=-1, Steps=8705, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1155, Total reward=0.8, Steps=8711, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1156, Total reward=-2.2, Steps=8728, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1157, Total reward=-1.1, Steps=8732, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1158, Total reward=-2.0, Steps=8747, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1159, Total reward=-1.1, Steps=8763, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1160, Total reward=-1.6, Steps=8772, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1161, Total reward=0.3, Steps=8783, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1162, Total reward=-1, Steps=8786, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1163, Total reward=-1.1, Steps=8791, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1164, Total reward=-0.3, Steps=8799, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1165, Total reward=-1.1, Steps=8804, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1166, Total reward=1, Steps=8807, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1167, Total reward=0.3, Steps=8819, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1168, Total reward=-1, Steps=8822, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1169, Total reward=0.7, Steps=8829, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1170, Total reward=0.7, Steps=8837, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1171, Total reward=-1.1, Steps=8842, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1172, Total reward=-0.8, Steps=8855, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1173, Total reward=-2.3, Steps=8873, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1174, Total reward=-1, Steps=8877, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1175, Total reward=-1.1, Steps=8893, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1176, Total reward=-1.4, Steps=8900, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1177, Total reward=-1.1, Steps=8904, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1178, Total reward=-1.2, Steps=8909, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1179, Total reward=-2.2, Steps=8926, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1180, Total reward=-1.3, Steps=8933, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1181, Total reward=-0.1, Steps=8939, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1182, Total reward=-2.2, Steps=8956, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1183, Total reward=-1.1, Steps=8960, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1184, Total reward=0.3, Steps=8971, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1185, Total reward=-1.0, Steps=8986, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1186, Total reward=-1, Steps=8989, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1187, Total reward=-1.1, Steps=8994, Training iteration=4\u001b[0m\n",
      "\u001b[34m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=1187, Total reward=-1, Steps=9000, Training iteration=4\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=1187, Total reward=-2.0, Steps=9000, Training iteration=4\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=1187, Total reward=-2.0, Steps=9000, Training iteration=4\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=1187, Total reward=-2.0, Steps=9000, Training iteration=4\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=1187, Total reward=-2.0, Steps=9000, Training iteration=4\u001b[0m\n",
      "\u001b[34m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = -1.8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1188, Total reward=1, Steps=9003, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1189, Total reward=0.5, Steps=9012, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1190, Total reward=-1, Steps=9015, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1191, Total reward=0, Steps=9020, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1192, Total reward=0.8, Steps=9026, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1193, Total reward=-1, Steps=9029, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1194, Total reward=-1, Steps=9033, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1195, Total reward=0.9, Steps=9039, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1196, Total reward=1, Steps=9043, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1197, Total reward=-0.4, Steps=9052, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1198, Total reward=-0.5, Steps=9062, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1199, Total reward=-1.3, Steps=9068, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1200, Total reward=-1.1, Steps=9072, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1201, Total reward=-1, Steps=9075, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1202, Total reward=-1.2, Steps=9080, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1203, Total reward=-1.3, Steps=9087, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1204, Total reward=-1, Steps=9090, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1205, Total reward=-1, Steps=9094, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1206, Total reward=-1.3, Steps=9101, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1207, Total reward=-1.1, Steps=9105, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1208, Total reward=-2.2, Steps=9122, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1209, Total reward=-1.2, Steps=9127, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1210, Total reward=-0.4, Steps=9136, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1211, Total reward=-1, Steps=9139, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1212, Total reward=-1, Steps=9142, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1213, Total reward=-1.1, Steps=9146, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1214, Total reward=-0.6, Steps=9157, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1215, Total reward=-2.0, Steps=9172, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1216, Total reward=-1, Steps=9175, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1217, Total reward=1, Steps=9180, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1218, Total reward=-1.3, Steps=9186, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1219, Total reward=-0.4, Steps=9195, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1220, Total reward=-1, Steps=9198, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1221, Total reward=-2.4, Steps=9217, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1222, Total reward=0.8, Steps=9223, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1223, Total reward=-1.1, Steps=9227, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1224, Total reward=-0.5, Steps=9237, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1225, Total reward=-1.4, Steps=9245, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1226, Total reward=-0.7, Steps=9257, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1227, Total reward=0.4, Steps=9268, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1228, Total reward=-1.2, Steps=9273, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1229, Total reward=-0.1, Steps=9279, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1230, Total reward=0.9, Steps=9284, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1231, Total reward=-1.0, Steps=9299, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1232, Total reward=-1.1, Steps=9303, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1233, Total reward=-1.1, Steps=9307, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1234, Total reward=-1, Steps=9311, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1235, Total reward=1, Steps=9315, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1236, Total reward=-0.5, Steps=9325, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1237, Total reward=-2.6, Steps=9346, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1238, Total reward=-1.2, Steps=9351, Training iteration=4\u001b[0m\n",
      "\u001b[34mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/8_Step-9351.ckpt.main_level.agent.main.online.onnx', '/opt/ml/output/data/checkpoint/8_Step-9351.ckpt.main_level.agent.main.online']\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1239, Total reward=-1.1, Steps=9355, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1240, Total reward=-1.2, Steps=9360, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1241, Total reward=-1, Steps=9364, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1242, Total reward=-2.2, Steps=9380, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1243, Total reward=-0.7, Steps=9392, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1244, Total reward=-1.2, Steps=9397, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1245, Total reward=-0.5, Steps=9407, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1246, Total reward=-1.0, Steps=9422, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1247, Total reward=-1.2, Steps=9428, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1248, Total reward=-1.2, Steps=9433, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1249, Total reward=-1, Steps=9436, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1250, Total reward=-1, Steps=9439, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1251, Total reward=-2.1, Steps=9455, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1252, Total reward=-0.9, Steps=9469, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1253, Total reward=0, Steps=9474, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1254, Total reward=-1, Steps=9477, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1255, Total reward=0.5, Steps=9486, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1256, Total reward=-1, Steps=9490, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1257, Total reward=-1.9, Steps=9503, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1258, Total reward=-0.6, Steps=9514, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1259, Total reward=-1.1, Steps=9519, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1260, Total reward=-2.1, Steps=9535, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1261, Total reward=0.9, Steps=9540, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1262, Total reward=-1.3, Steps=9547, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1263, Total reward=-0.7, Steps=9559, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1264, Total reward=-1.2, Steps=9576, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1265, Total reward=-0.7, Steps=9588, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1266, Total reward=0.8, Steps=9594, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1267, Total reward=0.7, Steps=9601, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1268, Total reward=-1, Steps=9605, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1269, Total reward=-0.4, Steps=9614, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1270, Total reward=-0.8, Steps=9627, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1271, Total reward=-1.0, Steps=9642, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1272, Total reward=1, Steps=9645, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1273, Total reward=0.8, Steps=9651, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1274, Total reward=0.5, Steps=9660, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1275, Total reward=-0.3, Steps=9668, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1276, Total reward=-1, Steps=9672, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1277, Total reward=-1.8, Steps=9684, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1278, Total reward=-1, Steps=9688, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1279, Total reward=0.7, Steps=9695, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1280, Total reward=-1, Steps=9698, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1281, Total reward=1, Steps=9702, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1282, Total reward=-1.2, Steps=9708, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1283, Total reward=-0.2, Steps=9725, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1284, Total reward=-1.5, Steps=9734, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1285, Total reward=0.8, Steps=9740, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1286, Total reward=-0.3, Steps=9748, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1287, Total reward=-2.1, Steps=9764, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1288, Total reward=-1.2, Steps=9769, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1289, Total reward=0.4, Steps=9779, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1290, Total reward=-2.3, Steps=9797, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1291, Total reward=-1, Steps=9800, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1292, Total reward=-1.1, Steps=9805, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1293, Total reward=-0.1, Steps=9811, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1294, Total reward=-1.3, Steps=9818, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1295, Total reward=-1.2, Steps=9823, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1296, Total reward=-1.0, Steps=9838, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1297, Total reward=-1.1, Steps=9843, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1298, Total reward=0.8, Steps=9849, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1299, Total reward=-0.4, Steps=9858, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1300, Total reward=-1.1, Steps=9862, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1301, Total reward=-1, Steps=9865, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1302, Total reward=-1, Steps=9868, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1303, Total reward=0.9, Steps=9873, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1304, Total reward=-1, Steps=9876, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1305, Total reward=-1.2, Steps=9882, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1306, Total reward=-0.4, Steps=9891, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1307, Total reward=-0.2, Steps=9898, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1308, Total reward=0.4, Steps=9908, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1309, Total reward=-1, Steps=9911, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1310, Total reward=-1.1, Steps=9915, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1311, Total reward=-0.1, Steps=9921, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1312, Total reward=-0.4, Steps=9930, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1313, Total reward=-1.2, Steps=9935, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1314, Total reward=-1.3, Steps=9941, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1315, Total reward=-0.2, Steps=9948, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1316, Total reward=-1, Steps=9951, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1317, Total reward=-1.1, Steps=9967, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1318, Total reward=-0.1, Steps=9973, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1319, Total reward=-1, Steps=9976, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1320, Total reward=1, Steps=9980, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1321, Total reward=-1.2, Steps=9986, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1322, Total reward=-1, Steps=9989, Training iteration=4\u001b[0m\n",
      "\u001b[34m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=1322, Total reward=-2.0, Steps=10000, Training iteration=4\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=1322, Total reward=-2.0, Steps=10000, Training iteration=4\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=1322, Total reward=-2.0, Steps=10000, Training iteration=4\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=1322, Total reward=-2.0, Steps=10000, Training iteration=4\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=1322, Total reward=-2.0, Steps=10000, Training iteration=4\u001b[0m\n",
      "\u001b[34m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = -2.0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1323, Total reward=-1.1, Steps=10004, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1324, Total reward=-0.5, Steps=10014, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1325, Total reward=-0.2, Steps=10021, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1326, Total reward=-0.3, Steps=10029, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1327, Total reward=-1.2, Steps=10034, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1328, Total reward=-0.3, Steps=10042, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1329, Total reward=-1, Steps=10045, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1330, Total reward=-1.1, Steps=10049, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1331, Total reward=-0.1, Steps=10055, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1332, Total reward=0.9, Steps=10060, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1333, Total reward=-0.7, Steps=10072, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1334, Total reward=-1.1, Steps=10076, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1335, Total reward=-1.1, Steps=10080, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1336, Total reward=-1.1, Steps=10096, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1337, Total reward=-0.6, Steps=10107, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1338, Total reward=0.9, Steps=10112, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1339, Total reward=-1.3, Steps=10118, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1340, Total reward=0.8, Steps=10124, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1341, Total reward=-0.9, Steps=10138, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1342, Total reward=1, Steps=10142, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1343, Total reward=-0.7, Steps=10154, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1344, Total reward=-0.8, Steps=10167, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1345, Total reward=-1.1, Steps=10171, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1346, Total reward=-0.7, Steps=10183, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1347, Total reward=-0.6, Steps=10194, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1348, Total reward=-0.2, Steps=10201, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1349, Total reward=-0.5, Steps=10211, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1350, Total reward=-1.1, Steps=10215, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1351, Total reward=-2.1, Steps=10231, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1352, Total reward=-1.5, Steps=10240, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1353, Total reward=-1, Steps=10243, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1354, Total reward=-1.1, Steps=10247, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1355, Total reward=-1, Steps=10250, Training iteration=4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1356, Total reward=-1.5, Steps=10259, Training iteration=4\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=0.01582465134561062, KL divergence=[0.], Entropy=[-0.02050075], training epoch=0, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.02404681034386158, KL divergence=[0.], Entropy=[-0.02036547], training epoch=1, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.03403943404555321, KL divergence=[0.], Entropy=[-0.02027713], training epoch=2, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.049096547067165375, KL divergence=[0.], Entropy=[-0.02029344], training epoch=3, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.055427998304367065, KL divergence=[0.], Entropy=[-0.02016669], training epoch=4, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.06470127403736115, KL divergence=[0.], Entropy=[-0.02013748], training epoch=5, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.07442045956850052, KL divergence=[0.], Entropy=[-0.02000511], training epoch=6, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.07398433238267899, KL divergence=[0.], Entropy=[-0.02001556], training epoch=7, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.08017945289611816, KL divergence=[0.], Entropy=[-0.01998859], training epoch=8, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.07975345849990845, KL divergence=[0.], Entropy=[-0.01993404], training epoch=9, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/9_Step-10259.ckpt.main_level.agent.main.online.onnx', '/opt/ml/output/data/checkpoint/9_Step-10259.ckpt.main_level.agent.main.online']\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1357, Total reward=-2.2, Steps=10276, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1358, Total reward=-1, Steps=10279, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1359, Total reward=-1, Steps=10283, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1360, Total reward=-0.4, Steps=10292, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1361, Total reward=-1.2, Steps=10297, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1362, Total reward=-1, Steps=10300, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1363, Total reward=0.9, Steps=10305, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1364, Total reward=-1, Steps=10308, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1365, Total reward=-1.3, Steps=10315, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1366, Total reward=-2.0, Steps=10330, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1367, Total reward=0.8, Steps=10336, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1368, Total reward=0.9, Steps=10341, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1369, Total reward=-1.1, Steps=10345, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1370, Total reward=-0.4, Steps=10354, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1371, Total reward=-0.1, Steps=10360, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1372, Total reward=-2.0, Steps=10375, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1373, Total reward=-1.4, Steps=10382, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1374, Total reward=0.8, Steps=10388, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1375, Total reward=-1, Steps=10391, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1376, Total reward=-1.1, Steps=10395, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1377, Total reward=-1, Steps=10398, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1378, Total reward=-2.4, Steps=10417, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1379, Total reward=0.6, Steps=10426, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1380, Total reward=1, Steps=10429, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1381, Total reward=0.6, Steps=10437, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1382, Total reward=-0.3, Steps=10445, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1383, Total reward=-1.1, Steps=10450, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1384, Total reward=-0.8, Steps=10463, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1385, Total reward=-0.4, Steps=10472, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1386, Total reward=-1.4, Steps=10480, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1387, Total reward=-1.1, Steps=10485, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1388, Total reward=0.9, Steps=10490, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1389, Total reward=-1.2, Steps=10507, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1390, Total reward=-1, Steps=10510, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1391, Total reward=1, Steps=10514, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1392, Total reward=0, Steps=10519, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1393, Total reward=-1.4, Steps=10527, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1394, Total reward=0.9, Steps=10532, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1395, Total reward=-1, Steps=10536, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1396, Total reward=-1, Steps=10539, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1397, Total reward=-1.6, Steps=10549, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1398, Total reward=-1, Steps=10552, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1399, Total reward=-0.5, Steps=10562, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1400, Total reward=-1.1, Steps=10566, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1401, Total reward=0.7, Steps=10572, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1402, Total reward=0.8, Steps=10577, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1403, Total reward=-1, Steps=10581, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1404, Total reward=-1.1, Steps=10585, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1405, Total reward=-1, Steps=10588, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1406, Total reward=-1.2, Steps=10593, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1407, Total reward=-2.1, Steps=10609, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1408, Total reward=-1.3, Steps=10627, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1409, Total reward=-0.8, Steps=10640, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1410, Total reward=-0.1, Steps=10646, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1411, Total reward=-1.1, Steps=10651, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1412, Total reward=-0.3, Steps=10659, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1413, Total reward=-1, Steps=10662, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1414, Total reward=-1.0, Steps=10677, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1415, Total reward=-1.2, Steps=10694, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1416, Total reward=0.8, Steps=10700, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1417, Total reward=0.7, Steps=10707, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1418, Total reward=-1.1, Steps=10711, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1419, Total reward=-1, Steps=10714, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1420, Total reward=-2.6, Steps=10735, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1421, Total reward=-1, Steps=10739, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1422, Total reward=-1.2, Steps=10744, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1423, Total reward=0.9, Steps=10749, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1424, Total reward=-1.8, Steps=10761, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1425, Total reward=-1.2, Steps=10766, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1426, Total reward=-1.2, Steps=10772, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1427, Total reward=-1, Steps=10775, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1428, Total reward=-1.3, Steps=10781, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1429, Total reward=0.8, Steps=10787, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1430, Total reward=-1.1, Steps=10792, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1431, Total reward=-1, Steps=10796, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1432, Total reward=-0.3, Steps=10804, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1433, Total reward=-1.2, Steps=10810, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1434, Total reward=-1, Steps=10813, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1435, Total reward=0.1, Steps=10826, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1436, Total reward=-2.0, Steps=10841, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1437, Total reward=0.8, Steps=10847, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1438, Total reward=1, Steps=10851, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1439, Total reward=-0.6, Steps=10862, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1440, Total reward=-1.4, Steps=10881, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1441, Total reward=-1.3, Steps=10888, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1442, Total reward=-1, Steps=10891, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1443, Total reward=-1.3, Steps=10898, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1444, Total reward=-2.0, Steps=10913, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1445, Total reward=0.8, Steps=10919, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1446, Total reward=-1, Steps=10922, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1447, Total reward=-1, Steps=10926, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1448, Total reward=-1, Steps=10929, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1449, Total reward=1, Steps=10933, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1450, Total reward=-1.1, Steps=10937, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1451, Total reward=-0.2, Steps=10944, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1452, Total reward=-1.2, Steps=10949, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1453, Total reward=-1, Steps=10953, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1454, Total reward=0.4, Steps=10964, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1455, Total reward=-1, Steps=10967, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1456, Total reward=0, Steps=10972, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1457, Total reward=0.8, Steps=10978, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1458, Total reward=-2.1, Steps=10994, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1459, Total reward=-1, Steps=10997, Training iteration=5\u001b[0m\n",
      "\u001b[34m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=1459, Total reward=-2.0, Steps=11000, Training iteration=5\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=1459, Total reward=-2.0, Steps=11000, Training iteration=5\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=1459, Total reward=-2.0, Steps=11000, Training iteration=5\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=1459, Total reward=-1, Steps=11000, Training iteration=5\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=1459, Total reward=-2.0, Steps=11000, Training iteration=5\u001b[0m\n",
      "\u001b[34m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = -1.8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1460, Total reward=-1.1, Steps=11004, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1461, Total reward=-1.2, Steps=11010, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1462, Total reward=-0.3, Steps=11018, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1463, Total reward=-1, Steps=11021, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1464, Total reward=-1, Steps=11024, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1465, Total reward=0.9, Steps=11030, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1466, Total reward=0.7, Steps=11037, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1467, Total reward=-0.4, Steps=11046, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1468, Total reward=-1, Steps=11049, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1469, Total reward=-1.2, Steps=11055, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1470, Total reward=-1.3, Steps=11062, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1471, Total reward=0, Steps=11067, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1472, Total reward=-1, Steps=11071, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1473, Total reward=0.9, Steps=11076, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1474, Total reward=-0.6, Steps=11087, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1475, Total reward=0.9, Steps=11092, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1476, Total reward=-0.7, Steps=11104, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1477, Total reward=-1.4, Steps=11112, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1478, Total reward=-0.6, Steps=11123, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1479, Total reward=1, Steps=11126, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1480, Total reward=-0.4, Steps=11135, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1481, Total reward=-1, Steps=11138, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1482, Total reward=-1, Steps=11141, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1483, Total reward=-1.3, Steps=11148, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1484, Total reward=-1, Steps=11151, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1485, Total reward=-1.1, Steps=11155, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1486, Total reward=0.6, Steps=11164, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1487, Total reward=-0.8, Steps=11177, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1488, Total reward=-1.3, Steps=11184, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1489, Total reward=-1, Steps=11187, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1490, Total reward=-1, Steps=11190, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1491, Total reward=0.9, Steps=11195, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1492, Total reward=0.7, Steps=11202, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1493, Total reward=-1, Steps=11205, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1494, Total reward=1, Steps=11208, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1495, Total reward=-1.3, Steps=11215, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1496, Total reward=-1.1, Steps=11219, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1497, Total reward=-1.1, Steps=11223, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1498, Total reward=-1, Steps=11226, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1499, Total reward=-1, Steps=11230, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1500, Total reward=-1.1, Steps=11235, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1501, Total reward=-1.1, Steps=11239, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1502, Total reward=-0.6, Steps=11250, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1503, Total reward=0.9, Steps=11255, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1504, Total reward=-0.8, Steps=11268, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1505, Total reward=-1.1, Steps=11272, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1506, Total reward=-0.5, Steps=11282, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1507, Total reward=-0.5, Steps=11292, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1508, Total reward=-1.3, Steps=11298, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1509, Total reward=0.9, Steps=11303, Training iteration=5\u001b[0m\n",
      "\u001b[34mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/10_Step-11303.ckpt.main_level.agent.main.online.onnx', '/opt/ml/output/data/checkpoint/10_Step-11303.ckpt.main_level.agent.main.online']\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1510, Total reward=-1, Steps=11307, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1511, Total reward=-1, Steps=11310, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1512, Total reward=-0.8, Steps=11323, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1513, Total reward=-1, Steps=11326, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1514, Total reward=-1, Steps=11329, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1515, Total reward=-1.3, Steps=11335, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1516, Total reward=-0.5, Steps=11345, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1517, Total reward=-0.7, Steps=11357, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1518, Total reward=-1, Steps=11360, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1519, Total reward=-1.1, Steps=11365, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1520, Total reward=-0.5, Steps=11375, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1521, Total reward=1, Steps=11379, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1522, Total reward=-1.2, Steps=11385, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1523, Total reward=-1.1, Steps=11389, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1524, Total reward=1, Steps=11393, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1525, Total reward=-2.3, Steps=11411, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1526, Total reward=-1.0, Steps=11426, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1527, Total reward=-1, Steps=11429, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1528, Total reward=-0.9, Steps=11443, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1529, Total reward=-0.4, Steps=11452, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1530, Total reward=-0.6, Steps=11463, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1531, Total reward=-1.1, Steps=11467, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1532, Total reward=-1.1, Steps=11472, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1533, Total reward=-2.0, Steps=11487, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1534, Total reward=0.8, Steps=11494, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1535, Total reward=-1, Steps=11497, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1536, Total reward=-1, Steps=11500, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1537, Total reward=-3.0, Steps=11524, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1538, Total reward=-2.3, Steps=11542, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1539, Total reward=-2.1, Steps=11558, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1540, Total reward=1, Steps=11562, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1541, Total reward=-0.3, Steps=11570, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1542, Total reward=0.8, Steps=11576, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1543, Total reward=-0.3, Steps=11584, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1544, Total reward=-1.1, Steps=11589, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1545, Total reward=-1, Steps=11592, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1546, Total reward=-1.2, Steps=11597, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1547, Total reward=-0.5, Steps=11607, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1548, Total reward=-0.9, Steps=11621, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1549, Total reward=-2.1, Steps=11637, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1550, Total reward=0, Steps=11642, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1551, Total reward=-1, Steps=11645, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1552, Total reward=-0.1, Steps=11651, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1553, Total reward=-1, Steps=11655, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1554, Total reward=1, Steps=11659, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1555, Total reward=0.9, Steps=11664, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1556, Total reward=-1, Steps=11667, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1557, Total reward=-1.2, Steps=11672, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1558, Total reward=-1, Steps=11675, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1559, Total reward=0.5, Steps=11684, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1560, Total reward=-0.3, Steps=11692, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1561, Total reward=-1, Steps=11695, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1562, Total reward=-1.2, Steps=11700, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1563, Total reward=-0.4, Steps=11709, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1564, Total reward=-1.2, Steps=11715, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1565, Total reward=-1.1, Steps=11720, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1566, Total reward=-1, Steps=11724, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1567, Total reward=-1, Steps=11727, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1568, Total reward=0.6, Steps=11735, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1569, Total reward=1, Steps=11739, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1570, Total reward=-1, Steps=11742, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1571, Total reward=-2.3, Steps=11760, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1572, Total reward=-0.4, Steps=11769, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1573, Total reward=-1, Steps=11772, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1574, Total reward=0.1, Steps=11785, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1575, Total reward=-1, Steps=11788, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1576, Total reward=-1.1, Steps=11793, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1577, Total reward=0, Steps=11798, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1578, Total reward=-1.5, Steps=11806, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1579, Total reward=-0.2, Steps=11813, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1580, Total reward=-1.1, Steps=11817, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1581, Total reward=-1.1, Steps=11821, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1582, Total reward=-1.4, Steps=11840, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1583, Total reward=-0.3, Steps=11848, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1584, Total reward=1, Steps=11852, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1585, Total reward=-1.1, Steps=11857, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1586, Total reward=-1, Steps=11860, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1587, Total reward=-1, Steps=11863, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1588, Total reward=-1.1, Steps=11868, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1589, Total reward=-1.1, Steps=11872, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1590, Total reward=-0.8, Steps=11885, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1591, Total reward=-0.3, Steps=11893, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1592, Total reward=1, Steps=11897, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1593, Total reward=1, Steps=11900, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1594, Total reward=-1.1, Steps=11904, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1595, Total reward=-1, Steps=11907, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1596, Total reward=-1, Steps=11910, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1597, Total reward=0.9, Steps=11915, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1598, Total reward=-1, Steps=11918, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1599, Total reward=-1, Steps=11921, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1600, Total reward=0.8, Steps=11927, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1601, Total reward=-1, Steps=11930, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1602, Total reward=-0.3, Steps=11938, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1603, Total reward=-1.1, Steps=11942, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1604, Total reward=0.1, Steps=11955, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1605, Total reward=-2.6, Steps=11976, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1606, Total reward=-1, Steps=11980, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1607, Total reward=0.9, Steps=11985, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1608, Total reward=-1.1, Steps=11990, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1609, Total reward=-1.6, Steps=11999, Training iteration=5\u001b[0m\n",
      "\u001b[34m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=1609, Total reward=-2.0, Steps=12000, Training iteration=5\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=1609, Total reward=-2.0, Steps=12000, Training iteration=5\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=1609, Total reward=0, Steps=12000, Training iteration=5\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=1609, Total reward=-2.0, Steps=12000, Training iteration=5\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=1609, Total reward=-2.0, Steps=12000, Training iteration=5\u001b[0m\n",
      "\u001b[34m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = -1.6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1610, Total reward=-1, Steps=12003, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1611, Total reward=-0.4, Steps=12012, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1612, Total reward=-1, Steps=12015, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1613, Total reward=-1.2, Steps=12020, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1614, Total reward=-0.8, Steps=12033, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1615, Total reward=0.8, Steps=12039, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1616, Total reward=-1, Steps=12043, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1617, Total reward=-1.1, Steps=12048, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1618, Total reward=-0.2, Steps=12055, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1619, Total reward=-0.7, Steps=12067, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1620, Total reward=0.9, Steps=12072, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1621, Total reward=-2.1, Steps=12088, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1622, Total reward=-2.0, Steps=12103, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1623, Total reward=-1, Steps=12106, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1624, Total reward=-0.6, Steps=12117, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1625, Total reward=-0.6, Steps=12128, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1626, Total reward=-1.7, Steps=12139, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1627, Total reward=-0.4, Steps=12148, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1628, Total reward=-1.7, Steps=12159, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1629, Total reward=-1.2, Steps=12164, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1630, Total reward=-1, Steps=12167, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1631, Total reward=-1, Steps=12170, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1632, Total reward=-0.5, Steps=12180, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1633, Total reward=-0.4, Steps=12189, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1634, Total reward=-1, Steps=12192, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1635, Total reward=-0.1, Steps=12198, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1636, Total reward=-0.1, Steps=12204, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1637, Total reward=-0.5, Steps=12214, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1638, Total reward=-1.5, Steps=12222, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1639, Total reward=-1.1, Steps=12226, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1640, Total reward=-0.6, Steps=12237, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1641, Total reward=-1.1, Steps=12242, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1642, Total reward=1, Steps=12246, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1643, Total reward=-1.1, Steps=12262, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1644, Total reward=0.7, Steps=12268, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1645, Total reward=-1.3, Steps=12275, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1646, Total reward=-1.1, Steps=12280, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1647, Total reward=-1.3, Steps=12287, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1648, Total reward=-1.1, Steps=12291, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1649, Total reward=-1.2, Steps=12297, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1650, Total reward=-0.3, Steps=12305, Training iteration=5\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1651, Total reward=-0.4, Steps=12314, Training iteration=5\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=0.01360343024134636, KL divergence=[0.], Entropy=[-0.01983211], training epoch=0, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.02689862623810768, KL divergence=[0.], Entropy=[-0.01943141], training epoch=1, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.04688534885644913, KL divergence=[0.], Entropy=[-0.01926159], training epoch=2, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.05630826950073242, KL divergence=[0.], Entropy=[-0.01921998], training epoch=3, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.06689810752868652, KL divergence=[0.], Entropy=[-0.01914997], training epoch=4, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.06837131828069687, KL divergence=[0.], Entropy=[-0.01910247], training epoch=5, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.07344391942024231, KL divergence=[0.], Entropy=[-0.0191335], training epoch=6, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.0813770592212677, KL divergence=[0.], Entropy=[-0.01923814], training epoch=7, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.07918167114257812, KL divergence=[0.], Entropy=[-0.01904314], training epoch=8, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.0815451592206955, KL divergence=[0.], Entropy=[-0.0191418], training epoch=9, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/11_Step-12314.ckpt.main_level.agent.main.online.onnx', '/opt/ml/output/data/checkpoint/11_Step-12314.ckpt.main_level.agent.main.online']\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1652, Total reward=0.9, Steps=12319, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1653, Total reward=-0.4, Steps=12328, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1654, Total reward=-0.6, Steps=12339, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1655, Total reward=-1, Steps=12343, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1656, Total reward=0, Steps=12348, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1657, Total reward=0, Steps=12353, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1658, Total reward=-0.5, Steps=12363, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1659, Total reward=0.9, Steps=12368, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1660, Total reward=-0.2, Steps=12375, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1661, Total reward=-1, Steps=12378, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1662, Total reward=0.9, Steps=12382, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1663, Total reward=0.9, Steps=12387, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1664, Total reward=-0.5, Steps=12397, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1665, Total reward=-0.6, Steps=12408, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1666, Total reward=1, Steps=12412, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1667, Total reward=-1, Steps=12415, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1668, Total reward=-1.2, Steps=12421, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1669, Total reward=0, Steps=12426, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1670, Total reward=-1, Steps=12429, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1671, Total reward=1, Steps=12433, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1672, Total reward=-1.4, Steps=12441, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1673, Total reward=1, Steps=12445, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1674, Total reward=-0.9, Steps=12459, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1675, Total reward=0, Steps=12464, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1676, Total reward=-1.1, Steps=12468, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1677, Total reward=-0.3, Steps=12476, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1678, Total reward=-0.2, Steps=12483, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1679, Total reward=-1.2, Steps=12489, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1680, Total reward=-2.5, Steps=12509, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1681, Total reward=-1.4, Steps=12516, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1682, Total reward=-2.0, Steps=12531, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1683, Total reward=-1, Steps=12534, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1684, Total reward=0.9, Steps=12539, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1685, Total reward=-1, Steps=12542, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1686, Total reward=-0.5, Steps=12552, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1687, Total reward=-0.8, Steps=12565, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1688, Total reward=-0.6, Steps=12576, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1689, Total reward=-0.5, Steps=12586, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1690, Total reward=1, Steps=12590, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1691, Total reward=-1.2, Steps=12596, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1692, Total reward=-1, Steps=12599, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1693, Total reward=1, Steps=12603, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1694, Total reward=-1, Steps=12607, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1695, Total reward=-0.5, Steps=12617, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1696, Total reward=-1.1, Steps=12621, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1697, Total reward=0.9, Steps=12625, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1698, Total reward=-1.1, Steps=12641, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1699, Total reward=-1, Steps=12644, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1700, Total reward=0.9, Steps=12649, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1701, Total reward=-0.3, Steps=12657, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1702, Total reward=-1.1, Steps=12661, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1703, Total reward=-0.5, Steps=12671, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1704, Total reward=-0.2, Steps=12678, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1705, Total reward=-1.0, Steps=12693, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1706, Total reward=-1.2, Steps=12698, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1707, Total reward=0.8, Steps=12704, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1708, Total reward=-2.2, Steps=12721, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1709, Total reward=-1.2, Steps=12726, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1710, Total reward=0.7, Steps=12733, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1711, Total reward=-0.6, Steps=12744, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1712, Total reward=-1, Steps=12747, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1713, Total reward=-0.3, Steps=12755, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1714, Total reward=-1.1, Steps=12760, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1715, Total reward=-1.2, Steps=12765, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1716, Total reward=0.7, Steps=12772, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1717, Total reward=-1, Steps=12775, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1718, Total reward=-0.9, Steps=12789, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1719, Total reward=0.9, Steps=12795, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1720, Total reward=-0.5, Steps=12805, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1721, Total reward=-1.2, Steps=12822, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1722, Total reward=-1, Steps=12825, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1723, Total reward=-1, Steps=12828, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1724, Total reward=0.8, Steps=12834, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1725, Total reward=-1.2, Steps=12840, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1726, Total reward=-0.7, Steps=12852, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1727, Total reward=0.9, Steps=12857, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1728, Total reward=0.9, Steps=12862, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1729, Total reward=-0.2, Steps=12869, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1730, Total reward=-0.3, Steps=12877, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1731, Total reward=1, Steps=12881, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1732, Total reward=-1.1, Steps=12886, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1733, Total reward=-0.7, Steps=12898, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1734, Total reward=-1.1, Steps=12902, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1735, Total reward=-1, Steps=12905, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1736, Total reward=-1, Steps=12908, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1737, Total reward=-2.1, Steps=12924, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1738, Total reward=0.9, Steps=12929, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1739, Total reward=-0.1, Steps=12935, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1740, Total reward=0.9, Steps=12940, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1741, Total reward=-0.4, Steps=12949, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1742, Total reward=0, Steps=12954, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1743, Total reward=-0.3, Steps=12962, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1744, Total reward=-1, Steps=12965, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1745, Total reward=-1, Steps=12969, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1746, Total reward=-1, Steps=12972, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1747, Total reward=0.8, Steps=12978, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1748, Total reward=-1, Steps=12981, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1749, Total reward=-1, Steps=12985, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1750, Total reward=1, Steps=12989, Training iteration=6\u001b[0m\n",
      "\u001b[34m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=1750, Total reward=0, Steps=13000, Training iteration=6\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=1750, Total reward=1, Steps=13000, Training iteration=6\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=1750, Total reward=0, Steps=13000, Training iteration=6\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=1750, Total reward=1, Steps=13000, Training iteration=6\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=1750, Total reward=1, Steps=13000, Training iteration=6\u001b[0m\n",
      "\u001b[34m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = 0.6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1751, Total reward=-0.1, Steps=13006, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1752, Total reward=-0.6, Steps=13017, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1753, Total reward=-1.1, Steps=13022, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1754, Total reward=-1, Steps=13025, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1755, Total reward=-1, Steps=13028, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1756, Total reward=0.8, Steps=13034, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1757, Total reward=1, Steps=13038, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1758, Total reward=-1, Steps=13041, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1759, Total reward=-1.7, Steps=13052, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1760, Total reward=-0.4, Steps=13061, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1761, Total reward=1, Steps=13065, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1762, Total reward=1, Steps=13069, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1763, Total reward=-0.2, Steps=13076, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1764, Total reward=1, Steps=13080, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1765, Total reward=-1.4, Steps=13087, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1766, Total reward=-1, Steps=13090, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1767, Total reward=-1.1, Steps=13094, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1768, Total reward=-1, Steps=13098, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1769, Total reward=-1, Steps=13102, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1770, Total reward=-1, Steps=13105, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1771, Total reward=1, Steps=13109, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1772, Total reward=-1.1, Steps=13113, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1773, Total reward=-0.4, Steps=13122, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1774, Total reward=-0.8, Steps=13135, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1775, Total reward=0.8, Steps=13141, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1776, Total reward=0.9, Steps=13146, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1777, Total reward=-1.1, Steps=13150, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1778, Total reward=-1.2, Steps=13156, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1779, Total reward=-1, Steps=13159, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1780, Total reward=1, Steps=13164, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1781, Total reward=-1.1, Steps=13169, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1782, Total reward=-1, Steps=13172, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1783, Total reward=0.9, Steps=13177, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1784, Total reward=1, Steps=13180, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1785, Total reward=1, Steps=13183, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1786, Total reward=-0.1, Steps=13189, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1787, Total reward=-1, Steps=13192, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1788, Total reward=0.8, Steps=13198, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1789, Total reward=-1.4, Steps=13205, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1790, Total reward=0.9, Steps=13210, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1791, Total reward=-1.1, Steps=13214, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1792, Total reward=-1, Steps=13217, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1793, Total reward=-0.1, Steps=13223, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1794, Total reward=0.9, Steps=13228, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1795, Total reward=-0.4, Steps=13237, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1796, Total reward=-0.5, Steps=13247, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1797, Total reward=-0.1, Steps=13253, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1798, Total reward=-0.2, Steps=13260, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1799, Total reward=-1.1, Steps=13264, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1800, Total reward=-0.6, Steps=13275, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1801, Total reward=-1.3, Steps=13282, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1802, Total reward=-1.2, Steps=13288, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1803, Total reward=0.9, Steps=13293, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1804, Total reward=1, Steps=13297, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1805, Total reward=-0.1, Steps=13303, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1806, Total reward=1, Steps=13306, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1807, Total reward=0.8, Steps=13312, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1808, Total reward=-1, Steps=13315, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1809, Total reward=0, Steps=13320, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1810, Total reward=-1, Steps=13323, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1811, Total reward=-1, Steps=13327, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1812, Total reward=-0.2, Steps=13334, Training iteration=6\u001b[0m\n",
      "\u001b[34mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/12_Step-13334.ckpt.main_level.agent.main.online.onnx', '/opt/ml/output/data/checkpoint/12_Step-13334.ckpt.main_level.agent.main.online']\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1813, Total reward=-1.1, Steps=13339, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1814, Total reward=-0.5, Steps=13349, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1815, Total reward=-1, Steps=13352, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1816, Total reward=-2.0, Steps=13367, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1817, Total reward=-1.1, Steps=13371, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1818, Total reward=-0.9, Steps=13395, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1819, Total reward=-1, Steps=13398, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1820, Total reward=-0.6, Steps=13409, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1821, Total reward=-1.2, Steps=13415, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1822, Total reward=0, Steps=13420, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1823, Total reward=-0.1, Steps=13426, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1824, Total reward=-1, Steps=13430, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1825, Total reward=1, Steps=13434, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1826, Total reward=-1, Steps=13438, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1827, Total reward=-0.9, Steps=13452, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1828, Total reward=0.7, Steps=13460, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1829, Total reward=-1, Steps=13463, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1830, Total reward=-1.2, Steps=13468, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1831, Total reward=0.8, Steps=13474, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1832, Total reward=-0.5, Steps=13484, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1833, Total reward=-1.2, Steps=13489, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1834, Total reward=-1, Steps=13492, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1835, Total reward=-0.3, Steps=13500, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1836, Total reward=-1, Steps=13503, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1837, Total reward=-1, Steps=13507, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1838, Total reward=-0.1, Steps=13513, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1839, Total reward=-1.4, Steps=13521, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1840, Total reward=-1.7, Steps=13532, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1841, Total reward=-1.2, Steps=13537, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1842, Total reward=-1, Steps=13540, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1843, Total reward=0.9, Steps=13545, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1844, Total reward=-0.3, Steps=13553, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1845, Total reward=-2.3, Steps=13571, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1846, Total reward=-1, Steps=13574, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1847, Total reward=0.8, Steps=13581, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1848, Total reward=-1.1, Steps=13586, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1849, Total reward=-2.0, Steps=13601, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1850, Total reward=-2.4, Steps=13620, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1851, Total reward=-0.3, Steps=13628, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1852, Total reward=0.9, Steps=13633, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1853, Total reward=-1.1, Steps=13637, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1854, Total reward=-0.1, Steps=13643, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1855, Total reward=-0.4, Steps=13652, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1856, Total reward=-1, Steps=13655, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1857, Total reward=-1, Steps=13659, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1858, Total reward=-0.5, Steps=13669, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1859, Total reward=-1, Steps=13672, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1860, Total reward=-1.4, Steps=13679, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1861, Total reward=-1.1, Steps=13684, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1862, Total reward=-2.0, Steps=13699, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1863, Total reward=-2.5, Steps=13719, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1864, Total reward=-1, Steps=13722, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1865, Total reward=-1.1, Steps=13726, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1866, Total reward=-1.1, Steps=13731, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1867, Total reward=0.7, Steps=13739, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1868, Total reward=-1, Steps=13742, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1869, Total reward=-1.4, Steps=13750, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1870, Total reward=-0.1, Steps=13756, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1871, Total reward=0.8, Steps=13762, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1872, Total reward=0.9, Steps=13767, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1873, Total reward=-1, Steps=13770, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1874, Total reward=-0.2, Steps=13777, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1875, Total reward=-1.1, Steps=13781, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1876, Total reward=-1.1, Steps=13786, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1877, Total reward=-1.3, Steps=13804, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1878, Total reward=0.6, Steps=13812, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1879, Total reward=-0.2, Steps=13819, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1880, Total reward=-1, Steps=13823, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1881, Total reward=-1.2, Steps=13840, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1882, Total reward=-0.2, Steps=13847, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1883, Total reward=-1.1, Steps=13851, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1884, Total reward=-1, Steps=13854, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1885, Total reward=0, Steps=13859, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1886, Total reward=1, Steps=13863, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1887, Total reward=-1.1, Steps=13867, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1888, Total reward=-1, Steps=13871, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1889, Total reward=1, Steps=13874, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1890, Total reward=-2.0, Steps=13889, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1891, Total reward=1, Steps=13893, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1892, Total reward=-2.2, Steps=13910, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1893, Total reward=-1.1, Steps=13915, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1894, Total reward=0, Steps=13920, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1895, Total reward=-1.1, Steps=13924, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1896, Total reward=-2.0, Steps=13939, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1897, Total reward=-0.6, Steps=13950, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1898, Total reward=-2.0, Steps=13965, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1899, Total reward=-1.1, Steps=13970, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1900, Total reward=-1.2, Steps=13975, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1901, Total reward=-1, Steps=13978, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1902, Total reward=-1.1, Steps=13982, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1903, Total reward=-0.4, Steps=13991, Training iteration=6\u001b[0m\n",
      "\u001b[34m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=1903, Total reward=-2.0, Steps=14000, Training iteration=6\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=1903, Total reward=0, Steps=14000, Training iteration=6\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=1903, Total reward=1, Steps=14000, Training iteration=6\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=1903, Total reward=1, Steps=14000, Training iteration=6\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=1903, Total reward=-2.0, Steps=14000, Training iteration=6\u001b[0m\n",
      "\u001b[34m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = -0.4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1904, Total reward=0.9, Steps=14005, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1905, Total reward=0.8, Steps=14011, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1906, Total reward=0.9, Steps=14015, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1907, Total reward=0.8, Steps=14022, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1908, Total reward=0.5, Steps=14031, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1909, Total reward=1, Steps=14035, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1910, Total reward=-1.2, Steps=14040, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1911, Total reward=-0.3, Steps=14048, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1912, Total reward=0.7, Steps=14055, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1913, Total reward=-0.2, Steps=14062, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1914, Total reward=-1.1, Steps=14066, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1915, Total reward=-1, Steps=14069, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1916, Total reward=1, Steps=14073, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1917, Total reward=-0.5, Steps=14083, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1918, Total reward=-1, Steps=14087, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1919, Total reward=-1.1, Steps=14091, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1920, Total reward=-1, Steps=14095, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1921, Total reward=0.9, Steps=14101, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1922, Total reward=-0.1, Steps=14107, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1923, Total reward=-1.1, Steps=14111, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1924, Total reward=-0.7, Steps=14123, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1925, Total reward=-1.5, Steps=14132, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1926, Total reward=1, Steps=14136, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1927, Total reward=1, Steps=14140, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1928, Total reward=-1, Steps=14143, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1929, Total reward=-0.2, Steps=14150, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1930, Total reward=0.9, Steps=14155, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1931, Total reward=-1.1, Steps=14159, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1932, Total reward=-1.1, Steps=14163, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1933, Total reward=1, Steps=14167, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1934, Total reward=-1.3, Steps=14174, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1935, Total reward=-1, Steps=14178, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1936, Total reward=-0.3, Steps=14186, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1937, Total reward=0.8, Steps=14192, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1938, Total reward=-0.2, Steps=14199, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1939, Total reward=-0.3, Steps=14207, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1940, Total reward=-0.2, Steps=14214, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1941, Total reward=-0.1, Steps=14220, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1942, Total reward=-0.2, Steps=14227, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1943, Total reward=-1, Steps=14231, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1944, Total reward=-0.1, Steps=14237, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1945, Total reward=-1.1, Steps=14242, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1946, Total reward=-0.9, Steps=14256, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1947, Total reward=-1.3, Steps=14263, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1948, Total reward=-1, Steps=14266, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1949, Total reward=-0.2, Steps=14273, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1950, Total reward=-0.1, Steps=14279, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1951, Total reward=-0.5, Steps=14289, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1952, Total reward=0.8, Steps=14295, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1953, Total reward=-0.8, Steps=14308, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1954, Total reward=-1, Steps=14312, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1955, Total reward=0.1, Steps=14326, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1956, Total reward=0.7, Steps=14334, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1957, Total reward=-1.1, Steps=14338, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1958, Total reward=-1, Steps=14341, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1959, Total reward=0.7, Steps=14348, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1960, Total reward=-0.3, Steps=14356, Training iteration=6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1961, Total reward=-0.3, Steps=14364, Training iteration=6\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=0.0224666316062212, KL divergence=[0.], Entropy=[-0.01863462], training epoch=0, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.019797075539827347, KL divergence=[0.], Entropy=[-0.01858926], training epoch=1, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.04776651784777641, KL divergence=[0.], Entropy=[-0.0185061], training epoch=2, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.054902248084545135, KL divergence=[0.], Entropy=[-0.01841186], training epoch=3, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.05551009625196457, KL divergence=[0.], Entropy=[-0.01827215], training epoch=4, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.06618063151836395, KL divergence=[0.], Entropy=[-0.01831051], training epoch=5, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.06702941656112671, KL divergence=[0.], Entropy=[-0.01826465], training epoch=6, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.07297232002019882, KL divergence=[0.], Entropy=[-0.01812666], training epoch=7, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.07202506810426712, KL divergence=[0.], Entropy=[-0.01812643], training epoch=8, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.0849413275718689, KL divergence=[0.], Entropy=[-0.01815845], training epoch=9, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/13_Step-14364.ckpt.main_level.agent.main.online.onnx', '/opt/ml/output/data/checkpoint/13_Step-14364.ckpt.main_level.agent.main.online']\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1962, Total reward=-1.1, Steps=14368, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1963, Total reward=-0.2, Steps=14375, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1964, Total reward=-2.2, Steps=14392, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1965, Total reward=0.9, Steps=14396, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1966, Total reward=0, Steps=14401, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1967, Total reward=-1, Steps=14404, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1968, Total reward=-1.1, Steps=14408, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1969, Total reward=-1, Steps=14411, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1970, Total reward=1, Steps=14415, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1971, Total reward=1, Steps=14419, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1972, Total reward=-0.1, Steps=14425, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1973, Total reward=-1.2, Steps=14431, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1974, Total reward=1, Steps=14435, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1975, Total reward=1, Steps=14439, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1976, Total reward=-0.5, Steps=14449, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1977, Total reward=-1, Steps=14452, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1978, Total reward=-1, Steps=14455, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1979, Total reward=-0.5, Steps=14465, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1980, Total reward=0, Steps=14470, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1981, Total reward=-1, Steps=14473, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1982, Total reward=-1, Steps=14476, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1983, Total reward=-1, Steps=14479, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1984, Total reward=1, Steps=14483, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1985, Total reward=-1, Steps=14487, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1986, Total reward=1, Steps=14491, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1987, Total reward=-1, Steps=14494, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1988, Total reward=-1, Steps=14498, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1989, Total reward=-1.1, Steps=14503, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1990, Total reward=0.8, Steps=14509, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1991, Total reward=0.3, Steps=14520, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1992, Total reward=-1, Steps=14524, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1993, Total reward=-0.1, Steps=14530, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1994, Total reward=-1.0, Steps=14545, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1995, Total reward=-0.1, Steps=14551, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1996, Total reward=-0.5, Steps=14561, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1997, Total reward=-1, Steps=14564, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1998, Total reward=-1, Steps=14567, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=1999, Total reward=0.9, Steps=14572, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2000, Total reward=0.9, Steps=14576, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2001, Total reward=-1, Steps=14579, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2002, Total reward=-2.3, Steps=14597, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2003, Total reward=0.9, Steps=14602, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2004, Total reward=-1, Steps=14605, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2005, Total reward=1, Steps=14608, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2006, Total reward=-2.0, Steps=14622, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2007, Total reward=-0.1, Steps=14628, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2008, Total reward=-0.8, Steps=14641, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2009, Total reward=-1, Steps=14645, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2010, Total reward=-1, Steps=14648, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2011, Total reward=-1.2, Steps=14653, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2012, Total reward=-0.2, Steps=14660, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2013, Total reward=-1, Steps=14664, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2014, Total reward=-0.9, Steps=14678, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2015, Total reward=1, Steps=14681, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2016, Total reward=-1.4, Steps=14689, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2017, Total reward=-1, Steps=14692, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2018, Total reward=-0.2, Steps=14699, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2019, Total reward=1, Steps=14703, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2020, Total reward=-0.3, Steps=14711, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2021, Total reward=1, Steps=14716, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2022, Total reward=0, Steps=14721, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2023, Total reward=-0.1, Steps=14727, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2024, Total reward=0.9, Steps=14732, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2025, Total reward=0.8, Steps=14738, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2026, Total reward=0.8, Steps=14744, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2027, Total reward=0.8, Steps=14750, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2028, Total reward=0.0, Steps=14764, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2029, Total reward=-1, Steps=14767, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2030, Total reward=-0.7, Steps=14779, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2031, Total reward=-1, Steps=14782, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2032, Total reward=-0.2, Steps=14789, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2033, Total reward=-1, Steps=14793, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2034, Total reward=-1, Steps=14796, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2035, Total reward=0.9, Steps=14801, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2036, Total reward=-0.2, Steps=14808, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2037, Total reward=-0.3, Steps=14816, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2038, Total reward=-1, Steps=14820, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2039, Total reward=-1, Steps=14823, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2040, Total reward=-1, Steps=14826, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2041, Total reward=-1, Steps=14829, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2042, Total reward=-1.1, Steps=14833, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2043, Total reward=-0.4, Steps=14842, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2044, Total reward=-0.1, Steps=14848, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2045, Total reward=-2.0, Steps=14863, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2046, Total reward=0.9, Steps=14868, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2047, Total reward=0.8, Steps=14874, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2048, Total reward=-1, Steps=14877, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2049, Total reward=-1.1, Steps=14881, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2050, Total reward=-0.5, Steps=14891, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2051, Total reward=-1.1, Steps=14895, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2052, Total reward=0.9, Steps=14900, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2053, Total reward=-0.2, Steps=14907, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2054, Total reward=-1, Steps=14910, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2055, Total reward=-0.9, Steps=14924, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2056, Total reward=-0.6, Steps=14935, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2057, Total reward=0.8, Steps=14941, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2058, Total reward=-0.1, Steps=14947, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2059, Total reward=-0.5, Steps=14957, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2060, Total reward=-1.1, Steps=14961, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2061, Total reward=-0.4, Steps=14970, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2062, Total reward=-1, Steps=14973, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2063, Total reward=-1.4, Steps=14981, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2064, Total reward=1, Steps=14985, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2065, Total reward=-0.1, Steps=14991, Training iteration=7\u001b[0m\n",
      "\u001b[34m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=2065, Total reward=0, Steps=15000, Training iteration=7\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=2065, Total reward=-2.0, Steps=15000, Training iteration=7\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=2065, Total reward=-2.0, Steps=15000, Training iteration=7\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=2065, Total reward=-2.0, Steps=15000, Training iteration=7\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=2065, Total reward=-2.0, Steps=15000, Training iteration=7\u001b[0m\n",
      "\u001b[34m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = -1.6\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2066, Total reward=0.9, Steps=15005, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2067, Total reward=-0.2, Steps=15012, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2068, Total reward=-1, Steps=15015, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2069, Total reward=-0.2, Steps=15032, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2070, Total reward=-1, Steps=15035, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2071, Total reward=-1.2, Steps=15040, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2072, Total reward=-1, Steps=15043, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2073, Total reward=-1, Steps=15046, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2074, Total reward=1, Steps=15049, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2075, Total reward=-0.2, Steps=15056, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2076, Total reward=-1, Steps=15060, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2077, Total reward=0.8, Steps=15066, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2078, Total reward=-0.1, Steps=15072, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2079, Total reward=0.9, Steps=15077, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2080, Total reward=0.9, Steps=15082, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2081, Total reward=-1.3, Steps=15089, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2082, Total reward=0, Steps=15094, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2083, Total reward=1, Steps=15098, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2084, Total reward=-0.1, Steps=15104, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2085, Total reward=-0.9, Steps=15118, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2086, Total reward=-2.0, Steps=15132, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2087, Total reward=-1.1, Steps=15136, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2088, Total reward=0.9, Steps=15141, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2089, Total reward=-2.2, Steps=15158, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2090, Total reward=-1, Steps=15161, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2091, Total reward=-0.6, Steps=15172, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2092, Total reward=0.9, Steps=15177, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2093, Total reward=-1, Steps=15180, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2094, Total reward=0.2, Steps=15192, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2095, Total reward=-0.5, Steps=15202, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2096, Total reward=-1.2, Steps=15207, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2097, Total reward=0.9, Steps=15212, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2098, Total reward=-0.4, Steps=15221, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2099, Total reward=-1.2, Steps=15227, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2100, Total reward=1, Steps=15231, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2101, Total reward=-0.4, Steps=15240, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2102, Total reward=-1.1, Steps=15244, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2103, Total reward=-0.1, Steps=15250, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2104, Total reward=1, Steps=15254, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2105, Total reward=-0.1, Steps=15260, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2106, Total reward=-1.1, Steps=15265, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2107, Total reward=-0.1, Steps=15271, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2108, Total reward=-1.7, Steps=15282, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2109, Total reward=0, Steps=15287, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2110, Total reward=-1.1, Steps=15291, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2111, Total reward=-0.2, Steps=15298, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2112, Total reward=-1, Steps=15301, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2113, Total reward=1, Steps=15305, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2114, Total reward=0.9, Steps=15310, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2115, Total reward=-1.1, Steps=15315, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2116, Total reward=-0.3, Steps=15323, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2117, Total reward=-1.1, Steps=15327, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2118, Total reward=-1, Steps=15331, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2119, Total reward=-1.2, Steps=15336, Training iteration=7\u001b[0m\n",
      "\u001b[34mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/14_Step-15337.ckpt.main_level.agent.main.online.onnx', '/opt/ml/output/data/checkpoint/14_Step-15337.ckpt.main_level.agent.main.online']\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2120, Total reward=0, Steps=15341, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2121, Total reward=-0.3, Steps=15349, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2122, Total reward=-0.2, Steps=15356, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2123, Total reward=-1, Steps=15359, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2124, Total reward=-1.3, Steps=15366, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2125, Total reward=0.9, Steps=15371, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2126, Total reward=-1, Steps=15374, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2127, Total reward=1, Steps=15377, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2128, Total reward=0.9, Steps=15382, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2129, Total reward=0.9, Steps=15387, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2130, Total reward=0, Steps=15392, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2131, Total reward=-2.0, Steps=15407, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2132, Total reward=1, Steps=15411, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2133, Total reward=-1, Steps=15414, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2134, Total reward=-1, Steps=15417, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2135, Total reward=-1, Steps=15420, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2136, Total reward=-1, Steps=15423, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2137, Total reward=-0.5, Steps=15433, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2138, Total reward=-1.1, Steps=15437, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2139, Total reward=1, Steps=15441, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2140, Total reward=-0.9, Steps=15455, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2141, Total reward=0.8, Steps=15461, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2142, Total reward=1, Steps=15465, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2143, Total reward=-0.4, Steps=15474, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2144, Total reward=-1, Steps=15478, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2145, Total reward=1, Steps=15482, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2146, Total reward=-0.1, Steps=15488, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2147, Total reward=-0.4, Steps=15497, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2148, Total reward=-1, Steps=15500, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2149, Total reward=-1, Steps=15503, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2150, Total reward=0.8, Steps=15509, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2151, Total reward=0.7, Steps=15516, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2152, Total reward=0.9, Steps=15521, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2153, Total reward=-1.1, Steps=15526, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2154, Total reward=0.7, Steps=15533, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2155, Total reward=1, Steps=15537, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2156, Total reward=-1.0, Steps=15552, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2157, Total reward=1, Steps=15556, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2158, Total reward=-1, Steps=15559, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2159, Total reward=1, Steps=15563, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2160, Total reward=-1, Steps=15566, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2161, Total reward=-1, Steps=15569, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2162, Total reward=-0.1, Steps=15575, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2163, Total reward=0, Steps=15580, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2164, Total reward=-2.1, Steps=15596, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2165, Total reward=1, Steps=15600, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2166, Total reward=-1, Steps=15603, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2167, Total reward=-1.1, Steps=15607, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2168, Total reward=-0.1, Steps=15613, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2169, Total reward=-1, Steps=15616, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2170, Total reward=1, Steps=15620, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2171, Total reward=1, Steps=15624, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2172, Total reward=1, Steps=15628, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2173, Total reward=-1, Steps=15631, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2174, Total reward=0.8, Steps=15637, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2175, Total reward=1, Steps=15641, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2176, Total reward=1, Steps=15644, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2177, Total reward=0.7, Steps=15651, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2178, Total reward=0.7, Steps=15658, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2179, Total reward=-0.1, Steps=15664, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2180, Total reward=0.7, Steps=15672, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2181, Total reward=-1, Steps=15675, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2182, Total reward=-1.1, Steps=15679, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2183, Total reward=-2.2, Steps=15696, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2184, Total reward=-0.2, Steps=15703, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2185, Total reward=-1.4, Steps=15711, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2186, Total reward=-1.1, Steps=15716, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2187, Total reward=1, Steps=15719, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2188, Total reward=-0.6, Steps=15730, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2189, Total reward=1, Steps=15734, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2190, Total reward=-1.1, Steps=15738, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2191, Total reward=0.8, Steps=15744, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2192, Total reward=-0.3, Steps=15752, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2193, Total reward=-0.7, Steps=15764, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2194, Total reward=0.7, Steps=15771, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2195, Total reward=-1, Steps=15775, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2196, Total reward=0.8, Steps=15781, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2197, Total reward=-1.1, Steps=15785, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2198, Total reward=1, Steps=15788, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2199, Total reward=-0.3, Steps=15796, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2200, Total reward=1, Steps=15800, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2201, Total reward=-1.2, Steps=15806, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2202, Total reward=0, Steps=15811, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2203, Total reward=-0.1, Steps=15817, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2204, Total reward=0.9, Steps=15822, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2205, Total reward=-0.3, Steps=15830, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2206, Total reward=-1.1, Steps=15834, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2207, Total reward=-1.1, Steps=15839, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2208, Total reward=-0.6, Steps=15850, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2209, Total reward=-2.3, Steps=15868, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2210, Total reward=1, Steps=15871, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2211, Total reward=-1, Steps=15874, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2212, Total reward=0.9, Steps=15879, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2213, Total reward=-0.2, Steps=15886, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2214, Total reward=0.9, Steps=15890, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2215, Total reward=-1, Steps=15894, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2216, Total reward=0, Steps=15899, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2217, Total reward=0, Steps=15904, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2218, Total reward=0, Steps=15909, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2219, Total reward=0.8, Steps=15916, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2220, Total reward=-1, Steps=15919, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2221, Total reward=-1, Steps=15923, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2222, Total reward=1, Steps=15927, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2223, Total reward=-1, Steps=15930, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2224, Total reward=-1, Steps=15933, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2225, Total reward=0.9, Steps=15937, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2226, Total reward=-1, Steps=15941, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2227, Total reward=-1, Steps=15944, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2228, Total reward=0.9, Steps=15949, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2229, Total reward=-1, Steps=15952, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2230, Total reward=-1.2, Steps=15957, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2231, Total reward=-0.1, Steps=15963, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2232, Total reward=0.9, Steps=15968, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2233, Total reward=-0.7, Steps=15980, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2234, Total reward=-0.3, Steps=15988, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2235, Total reward=0.7, Steps=15995, Training iteration=7\u001b[0m\n",
      "\u001b[34m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=2235, Total reward=0, Steps=16000, Training iteration=7\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=2235, Total reward=1, Steps=16000, Training iteration=7\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=2235, Total reward=-2.0, Steps=16000, Training iteration=7\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=2235, Total reward=1, Steps=16000, Training iteration=7\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=2235, Total reward=-2.0, Steps=16000, Training iteration=7\u001b[0m\n",
      "\u001b[34m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = -0.4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2236, Total reward=-1, Steps=16004, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2237, Total reward=1, Steps=16008, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2238, Total reward=-1.1, Steps=16013, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2239, Total reward=-0.1, Steps=16019, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2240, Total reward=-1, Steps=16023, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2241, Total reward=-1.1, Steps=16027, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2242, Total reward=-0.1, Steps=16033, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2243, Total reward=-0.1, Steps=16039, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2244, Total reward=-1, Steps=16042, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2245, Total reward=0, Steps=16047, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2246, Total reward=-1, Steps=16050, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2247, Total reward=1, Steps=16055, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2248, Total reward=-0.3, Steps=16063, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2249, Total reward=0, Steps=16068, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2250, Total reward=-1, Steps=16071, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2251, Total reward=1, Steps=16075, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2252, Total reward=-1, Steps=16078, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2253, Total reward=-0.9, Steps=16092, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2254, Total reward=-0.3, Steps=16100, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2255, Total reward=-1, Steps=16103, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2256, Total reward=-0.5, Steps=16113, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2257, Total reward=-1.2, Steps=16119, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2258, Total reward=0.1, Steps=16132, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2259, Total reward=-0.9, Steps=16146, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2260, Total reward=-1, Steps=16149, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2261, Total reward=1, Steps=16153, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2262, Total reward=1, Steps=16157, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2263, Total reward=0.8, Steps=16163, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2264, Total reward=-1.2, Steps=16169, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2265, Total reward=1, Steps=16173, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2266, Total reward=-1, Steps=16177, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2267, Total reward=-0.8, Steps=16190, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2268, Total reward=-1, Steps=16193, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2269, Total reward=-1.2, Steps=16199, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2270, Total reward=-0.4, Steps=16208, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2271, Total reward=-0.4, Steps=16217, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2272, Total reward=-1, Steps=16220, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2273, Total reward=-0.2, Steps=16227, Training iteration=7\u001b[0m\n",
      "\u001b[34mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/15_Step-16227.ckpt.main_level.agent.main.online.onnx', '/opt/ml/output/data/checkpoint/15_Step-16227.ckpt.main_level.agent.main.online']\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2274, Total reward=-1, Steps=16231, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2275, Total reward=-0.1, Steps=16237, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2276, Total reward=-1, Steps=16240, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2277, Total reward=-1, Steps=16243, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2278, Total reward=-1.1, Steps=16247, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2279, Total reward=-0.1, Steps=16263, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2280, Total reward=-0.2, Steps=16270, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2281, Total reward=-1, Steps=16273, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2282, Total reward=-2.0, Steps=16288, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2283, Total reward=-1.6, Steps=16297, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2284, Total reward=-0.2, Steps=16304, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2285, Total reward=-0.3, Steps=16312, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2286, Total reward=-1.2, Steps=16318, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2287, Total reward=-1, Steps=16321, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2288, Total reward=-1.1, Steps=16326, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2289, Total reward=1, Steps=16330, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2290, Total reward=-1.2, Steps=16336, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2291, Total reward=-1.1, Steps=16340, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2292, Total reward=1, Steps=16344, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2293, Total reward=-1, Steps=16347, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2294, Total reward=1, Steps=16351, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2295, Total reward=-1.1, Steps=16355, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2296, Total reward=-0.4, Steps=16364, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2297, Total reward=-1, Steps=16367, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2298, Total reward=-1, Steps=16370, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2299, Total reward=0.9, Steps=16375, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2300, Total reward=-0.2, Steps=16382, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2301, Total reward=0.9, Steps=16388, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2302, Total reward=0.8, Steps=16395, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2303, Total reward=-0.1, Steps=16401, Training iteration=7\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2304, Total reward=-0.8, Steps=16414, Training iteration=7\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=0.010458306409418583, KL divergence=[0.], Entropy=[-0.01738826], training epoch=0, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.02542349323630333, KL divergence=[0.], Entropy=[-0.01718571], training epoch=1, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.04506024718284607, KL divergence=[0.], Entropy=[-0.01713078], training epoch=2, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.052803706377744675, KL divergence=[0.], Entropy=[-0.0170179], training epoch=3, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.05665535479784012, KL divergence=[0.], Entropy=[-0.01694747], training epoch=4, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.06386739760637283, KL divergence=[0.], Entropy=[-0.0169301], training epoch=5, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.06786041706800461, KL divergence=[0.], Entropy=[-0.01676279], training epoch=6, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.07818668335676193, KL divergence=[0.], Entropy=[-0.01681825], training epoch=7, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.07228213548660278, KL divergence=[0.], Entropy=[-0.01686119], training epoch=8, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.07197292149066925, KL divergence=[0.], Entropy=[-0.01676611], training epoch=9, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2305, Total reward=-2.1, Steps=16430, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2306, Total reward=-1.1, Steps=16434, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2307, Total reward=-1, Steps=16437, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2308, Total reward=-1, Steps=16440, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2309, Total reward=-1, Steps=16443, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2310, Total reward=-1, Steps=16446, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2311, Total reward=-0.1, Steps=16452, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2312, Total reward=-0.1, Steps=16458, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2313, Total reward=1, Steps=16462, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2314, Total reward=-1.3, Steps=16469, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2315, Total reward=1, Steps=16474, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2316, Total reward=-0.3, Steps=16482, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2317, Total reward=0.9, Steps=16487, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2318, Total reward=-0.3, Steps=16495, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2319, Total reward=-0.3, Steps=16503, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2320, Total reward=-0.2, Steps=16510, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2321, Total reward=-1, Steps=16514, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2322, Total reward=-1.1, Steps=16519, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2323, Total reward=1, Steps=16523, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2324, Total reward=1, Steps=16527, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2325, Total reward=-0.1, Steps=16533, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2326, Total reward=-0.3, Steps=16541, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2327, Total reward=-0.1, Steps=16547, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2328, Total reward=-1.1, Steps=16551, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2329, Total reward=1, Steps=16554, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2330, Total reward=0, Steps=16559, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2331, Total reward=0.9, Steps=16564, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2332, Total reward=-2.0, Steps=16578, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2333, Total reward=0, Steps=16583, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2334, Total reward=0, Steps=16588, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2335, Total reward=-0.2, Steps=16595, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2336, Total reward=-0.2, Steps=16602, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2337, Total reward=0.8, Steps=16608, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2338, Total reward=-1.1, Steps=16612, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2339, Total reward=-0.2, Steps=16619, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2340, Total reward=0.5, Steps=16628, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2341, Total reward=-1, Steps=16631, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2342, Total reward=1, Steps=16635, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2343, Total reward=-0.9, Steps=16649, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2344, Total reward=-1, Steps=16652, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2345, Total reward=0, Steps=16657, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2346, Total reward=-1.2, Steps=16663, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2347, Total reward=-0.2, Steps=16670, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2348, Total reward=0, Steps=16675, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2349, Total reward=-0.5, Steps=16685, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2350, Total reward=0.7, Steps=16692, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2351, Total reward=1, Steps=16696, Training iteration=8\u001b[0m\n",
      "\u001b[34mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/16_Step-16696.ckpt.main_level.agent.main.online.onnx', '/opt/ml/output/data/checkpoint/16_Step-16696.ckpt.main_level.agent.main.online']\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2352, Total reward=-1, Steps=16699, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2353, Total reward=-2.0, Steps=16714, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2354, Total reward=-1.3, Steps=16721, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2355, Total reward=-1.0, Steps=16736, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2356, Total reward=-0.3, Steps=16744, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2357, Total reward=0.8, Steps=16750, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2358, Total reward=-1, Steps=16753, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2359, Total reward=-0.1, Steps=16759, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2360, Total reward=-1.2, Steps=16765, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2361, Total reward=-1.2, Steps=16771, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2362, Total reward=0.9, Steps=16776, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2363, Total reward=-1.7, Steps=16787, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2364, Total reward=-0.1, Steps=16793, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2365, Total reward=-1, Steps=16796, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2366, Total reward=-0.4, Steps=16805, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2367, Total reward=-0.3, Steps=16813, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2368, Total reward=-1, Steps=16816, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2369, Total reward=0, Steps=16821, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2370, Total reward=-0.3, Steps=16829, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2371, Total reward=-1, Steps=16833, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2372, Total reward=-1.6, Steps=16842, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2373, Total reward=1, Steps=16846, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2374, Total reward=1, Steps=16850, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2375, Total reward=-0.1, Steps=16856, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2376, Total reward=-0.2, Steps=16863, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2377, Total reward=1, Steps=16867, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2378, Total reward=1, Steps=16871, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2379, Total reward=-0.2, Steps=16878, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2380, Total reward=-2.1, Steps=16894, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2381, Total reward=0, Steps=16899, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2382, Total reward=-1, Steps=16902, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2383, Total reward=-0.6, Steps=16913, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2384, Total reward=1, Steps=16917, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2385, Total reward=1, Steps=16921, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2386, Total reward=-1, Steps=16924, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2387, Total reward=0, Steps=16929, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2388, Total reward=1, Steps=16933, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2389, Total reward=-2.0, Steps=16948, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2390, Total reward=-0.6, Steps=16959, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2391, Total reward=1, Steps=16963, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2392, Total reward=-0.3, Steps=16971, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2393, Total reward=-1, Steps=16974, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2394, Total reward=-1, Steps=16977, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2395, Total reward=-0.3, Steps=16985, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2396, Total reward=-1, Steps=16988, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2397, Total reward=0.7, Steps=16995, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2398, Total reward=0.9, Steps=17000, Training iteration=8\u001b[0m\n",
      "\u001b[34m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=2398, Total reward=0, Steps=17000, Training iteration=8\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=2398, Total reward=1, Steps=17000, Training iteration=8\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=2398, Total reward=1, Steps=17000, Training iteration=8\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=2398, Total reward=-2.0, Steps=17000, Training iteration=8\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=2398, Total reward=0, Steps=17000, Training iteration=8\u001b[0m\n",
      "\u001b[34m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = 0.0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2399, Total reward=0.6, Steps=17008, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2400, Total reward=-1.3, Steps=17015, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2401, Total reward=0.6, Steps=17023, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2402, Total reward=-0.3, Steps=17031, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2403, Total reward=-0.1, Steps=17037, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2404, Total reward=1, Steps=17041, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2405, Total reward=-1, Steps=17044, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2406, Total reward=-0.1, Steps=17050, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2407, Total reward=0.4, Steps=17060, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2408, Total reward=0.8, Steps=17066, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2409, Total reward=1, Steps=17070, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2410, Total reward=-1.2, Steps=17075, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2411, Total reward=-1.6, Steps=17085, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2412, Total reward=-1, Steps=17088, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2413, Total reward=-1.1, Steps=17093, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2414, Total reward=1, Steps=17097, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2415, Total reward=-1, Steps=17101, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2416, Total reward=-0.1, Steps=17107, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2417, Total reward=1, Steps=17111, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2418, Total reward=-0.4, Steps=17120, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2419, Total reward=0, Steps=17125, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2420, Total reward=-0.3, Steps=17133, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2421, Total reward=1, Steps=17137, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2422, Total reward=0.9, Steps=17143, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2423, Total reward=-0.6, Steps=17154, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2424, Total reward=-0.1, Steps=17160, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2425, Total reward=-0.1, Steps=17166, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2426, Total reward=-0.1, Steps=17172, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2427, Total reward=-1, Steps=17175, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2428, Total reward=0, Steps=17180, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2429, Total reward=-0.4, Steps=17189, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2430, Total reward=0, Steps=17194, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2431, Total reward=1, Steps=17198, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2432, Total reward=-0.2, Steps=17205, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2433, Total reward=0.8, Steps=17211, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2434, Total reward=-1.1, Steps=17215, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2435, Total reward=-1, Steps=17218, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2436, Total reward=-1.1, Steps=17222, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2437, Total reward=-1, Steps=17225, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2438, Total reward=-1.1, Steps=17230, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2439, Total reward=0, Steps=17235, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2440, Total reward=-0.1, Steps=17241, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2441, Total reward=-0.7, Steps=17253, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2442, Total reward=0, Steps=17258, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2443, Total reward=-1, Steps=17261, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2444, Total reward=1, Steps=17265, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2445, Total reward=-1.1, Steps=17269, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2446, Total reward=-0.4, Steps=17278, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2447, Total reward=-1.3, Steps=17285, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2448, Total reward=1, Steps=17289, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2449, Total reward=-1, Steps=17292, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2450, Total reward=-0.4, Steps=17301, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2451, Total reward=1, Steps=17305, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2452, Total reward=0, Steps=17310, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2453, Total reward=0.7, Steps=17317, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2454, Total reward=-2.0, Steps=17332, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2455, Total reward=0.9, Steps=17338, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2456, Total reward=1, Steps=17342, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2457, Total reward=1, Steps=17346, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2458, Total reward=-1, Steps=17350, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2459, Total reward=-0.1, Steps=17356, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2460, Total reward=-0.8, Steps=17369, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2461, Total reward=-0.2, Steps=17376, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2462, Total reward=-1, Steps=17379, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2463, Total reward=-1, Steps=17382, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2464, Total reward=1, Steps=17386, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2465, Total reward=-0.3, Steps=17394, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2466, Total reward=1, Steps=17398, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2467, Total reward=0.9, Steps=17403, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2468, Total reward=0.8, Steps=17409, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2469, Total reward=-1.1, Steps=17414, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2470, Total reward=-0.2, Steps=17421, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2471, Total reward=0, Steps=17426, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2472, Total reward=0, Steps=17431, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2473, Total reward=0.8, Steps=17437, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2474, Total reward=-1.3, Steps=17444, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2475, Total reward=0, Steps=17449, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2476, Total reward=0.8, Steps=17455, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2477, Total reward=0.6, Steps=17463, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2478, Total reward=-1, Steps=17466, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2479, Total reward=0, Steps=17471, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2480, Total reward=0.9, Steps=17476, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2481, Total reward=-1.2, Steps=17481, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2482, Total reward=0.7, Steps=17488, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2483, Total reward=-1.2, Steps=17494, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2484, Total reward=0.9, Steps=17499, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2485, Total reward=0.8, Steps=17505, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2486, Total reward=0, Steps=17510, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2487, Total reward=-1, Steps=17514, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2488, Total reward=-0.2, Steps=17521, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2489, Total reward=-1.3, Steps=17527, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2490, Total reward=-1, Steps=17530, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2491, Total reward=-1.1, Steps=17534, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2492, Total reward=-1, Steps=17537, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2493, Total reward=-1, Steps=17540, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2494, Total reward=-0.2, Steps=17547, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2495, Total reward=1, Steps=17551, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2496, Total reward=0.9, Steps=17556, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2497, Total reward=-0.3, Steps=17564, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2498, Total reward=-1, Steps=17568, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2499, Total reward=-1.3, Steps=17575, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2500, Total reward=-0.9, Steps=17589, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2501, Total reward=-0.1, Steps=17595, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2502, Total reward=1, Steps=17599, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2503, Total reward=-0.2, Steps=17606, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2504, Total reward=-0.3, Steps=17614, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2505, Total reward=0.9, Steps=17619, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2506, Total reward=1, Steps=17623, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2507, Total reward=0.7, Steps=17630, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2508, Total reward=-1.2, Steps=17636, Training iteration=8\u001b[0m\n",
      "\u001b[34mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/17_Step-17636.ckpt.main_level.agent.main.online.onnx', '/opt/ml/output/data/checkpoint/17_Step-17636.ckpt.main_level.agent.main.online']\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2509, Total reward=-1, Steps=17639, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2510, Total reward=0, Steps=17644, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2511, Total reward=-0.4, Steps=17653, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2512, Total reward=-0.1, Steps=17659, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2513, Total reward=-0.6, Steps=17670, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2514, Total reward=-0.1, Steps=17676, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2515, Total reward=1, Steps=17680, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2516, Total reward=0.9, Steps=17685, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2517, Total reward=-0.3, Steps=17693, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2518, Total reward=0.9, Steps=17698, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2519, Total reward=1, Steps=17702, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2520, Total reward=-0.1, Steps=17708, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2521, Total reward=-0.1, Steps=17714, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2522, Total reward=-0.5, Steps=17724, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2523, Total reward=0.8, Steps=17730, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2524, Total reward=-0.3, Steps=17738, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2525, Total reward=-1, Steps=17741, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2526, Total reward=1, Steps=17745, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2527, Total reward=-0.2, Steps=17752, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2528, Total reward=-1.2, Steps=17757, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2529, Total reward=-1.2, Steps=17763, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2530, Total reward=0.8, Steps=17769, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2531, Total reward=-0.1, Steps=17775, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2532, Total reward=-0.4, Steps=17784, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2533, Total reward=-0.4, Steps=17793, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2534, Total reward=-1, Steps=17796, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2535, Total reward=0, Steps=17801, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2536, Total reward=1, Steps=17805, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2537, Total reward=0.8, Steps=17811, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2538, Total reward=-0.7, Steps=17823, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2539, Total reward=1, Steps=17827, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2540, Total reward=1, Steps=17831, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2541, Total reward=0.9, Steps=17836, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2542, Total reward=-0.4, Steps=17845, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2543, Total reward=-0.1, Steps=17851, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2544, Total reward=0.8, Steps=17857, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2545, Total reward=0.8, Steps=17863, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2546, Total reward=-0.5, Steps=17873, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2547, Total reward=-1.1, Steps=17877, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2548, Total reward=-0.3, Steps=17885, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2549, Total reward=-1.2, Steps=17890, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2550, Total reward=0.7, Steps=17897, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2551, Total reward=0, Steps=17902, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2552, Total reward=-0.2, Steps=17909, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2553, Total reward=1, Steps=17913, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2554, Total reward=0.9, Steps=17918, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2555, Total reward=-0.2, Steps=17925, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2556, Total reward=0.7, Steps=17932, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2557, Total reward=0.8, Steps=17938, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2558, Total reward=-1, Steps=17941, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2559, Total reward=1, Steps=17945, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2560, Total reward=-1, Steps=17948, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2561, Total reward=-0.7, Steps=17960, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2562, Total reward=-1, Steps=17963, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2563, Total reward=0, Steps=17968, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2564, Total reward=1, Steps=17972, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2565, Total reward=-1, Steps=17975, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2566, Total reward=1, Steps=17979, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2567, Total reward=-1.1, Steps=17984, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2568, Total reward=-0.2, Steps=17991, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2569, Total reward=0, Steps=17996, Training iteration=8\u001b[0m\n",
      "\u001b[34m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=2569, Total reward=-2.0, Steps=18000, Training iteration=8\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=2569, Total reward=0, Steps=18000, Training iteration=8\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=2569, Total reward=1, Steps=18000, Training iteration=8\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=2569, Total reward=0, Steps=18000, Training iteration=8\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=2569, Total reward=1, Steps=18000, Training iteration=8\u001b[0m\n",
      "\u001b[34m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = 0.0\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2570, Total reward=0.4, Steps=18010, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2571, Total reward=1, Steps=18014, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2572, Total reward=-0.5, Steps=18024, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2573, Total reward=-1, Steps=18027, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2574, Total reward=1, Steps=18031, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2575, Total reward=0.9, Steps=18036, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2576, Total reward=-1, Steps=18039, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2577, Total reward=0.9, Steps=18044, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2578, Total reward=-1, Steps=18047, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2579, Total reward=-1, Steps=18050, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2580, Total reward=-1, Steps=18054, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2581, Total reward=0, Steps=18059, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2582, Total reward=1, Steps=18063, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2583, Total reward=0.9, Steps=18068, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2584, Total reward=1, Steps=18072, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2585, Total reward=-1, Steps=18075, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2586, Total reward=-0.5, Steps=18085, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2587, Total reward=1, Steps=18089, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2588, Total reward=-1, Steps=18092, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2589, Total reward=0.9, Steps=18098, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2590, Total reward=0.9, Steps=18103, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2591, Total reward=0.8, Steps=18109, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2592, Total reward=-0.1, Steps=18115, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2593, Total reward=-0.3, Steps=18123, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2594, Total reward=0.9, Steps=18128, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2595, Total reward=-0.4, Steps=18137, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2596, Total reward=-1.1, Steps=18141, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2597, Total reward=1, Steps=18145, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2598, Total reward=-1, Steps=18148, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2599, Total reward=0, Steps=18153, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2600, Total reward=-0.3, Steps=18161, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2601, Total reward=-0.2, Steps=18168, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2602, Total reward=-1.5, Steps=18177, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2603, Total reward=-0.1, Steps=18183, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2604, Total reward=-1, Steps=18187, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2605, Total reward=-1.3, Steps=18194, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2606, Total reward=-1.2, Steps=18200, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2607, Total reward=1, Steps=18204, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2608, Total reward=-1.1, Steps=18208, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2609, Total reward=0, Steps=18213, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2610, Total reward=1, Steps=18217, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2611, Total reward=-0.3, Steps=18225, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2612, Total reward=-2.1, Steps=18241, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2613, Total reward=-0.5, Steps=18251, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2614, Total reward=-1, Steps=18254, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2615, Total reward=1, Steps=18258, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2616, Total reward=0.8, Steps=18264, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2617, Total reward=-0.4, Steps=18273, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2618, Total reward=-0.6, Steps=18284, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2619, Total reward=0, Steps=18289, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2620, Total reward=-1.2, Steps=18294, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2621, Total reward=-2.0, Steps=18309, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2622, Total reward=1, Steps=18313, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2623, Total reward=0.9, Steps=18318, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2624, Total reward=1, Steps=18322, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2625, Total reward=1, Steps=18326, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2626, Total reward=0.8, Steps=18332, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2627, Total reward=1, Steps=18336, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2628, Total reward=-1, Steps=18339, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2629, Total reward=-1, Steps=18343, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2630, Total reward=-1.1, Steps=18347, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2631, Total reward=1, Steps=18351, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2632, Total reward=-1.1, Steps=18355, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2633, Total reward=0.8, Steps=18361, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2634, Total reward=1, Steps=18365, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2635, Total reward=-1.6, Steps=18375, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2636, Total reward=-0.2, Steps=18382, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2637, Total reward=-1.1, Steps=18386, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2638, Total reward=-1, Steps=18389, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2639, Total reward=-1, Steps=18392, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2640, Total reward=-0.2, Steps=18399, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2641, Total reward=-0.6, Steps=18410, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2642, Total reward=-2.0, Steps=18425, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2643, Total reward=-2.1, Steps=18441, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2644, Total reward=0.9, Steps=18446, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2645, Total reward=-1, Steps=18449, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2646, Total reward=-1, Steps=18452, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2647, Total reward=-0.1, Steps=18458, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2648, Total reward=-1, Steps=18461, Training iteration=8\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2649, Total reward=-0.6, Steps=18472, Training iteration=8\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=0.008765225298702717, KL divergence=[0.], Entropy=[-0.0160684], training epoch=0, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.023914819583296776, KL divergence=[0.], Entropy=[-0.0155838], training epoch=1, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.044635970145463943, KL divergence=[0.], Entropy=[-0.01549138], training epoch=2, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.05940781533718109, KL divergence=[0.], Entropy=[-0.01538462], training epoch=3, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.06174328923225403, KL divergence=[0.], Entropy=[-0.0152418], training epoch=4, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.06485819816589355, KL divergence=[0.], Entropy=[-0.01513074], training epoch=5, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.07167886942625046, KL divergence=[0.], Entropy=[-0.01509865], training epoch=6, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.0758976936340332, KL divergence=[0.], Entropy=[-0.01512928], training epoch=7, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.07423082739114761, KL divergence=[0.], Entropy=[-0.01499755], training epoch=8, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mPolicy training> Surrogate loss=-0.07422851026058197, KL divergence=[0.], Entropy=[-0.0150212], training epoch=9, learning_rate=0.001\u001b[0m\n",
      "\u001b[34mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/18_Step-18472.ckpt.main_level.agent.main.online.onnx', '/opt/ml/output/data/checkpoint/18_Step-18472.ckpt.main_level.agent.main.online']\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2650, Total reward=-1.1, Steps=18476, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2651, Total reward=0, Steps=18481, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2652, Total reward=1, Steps=18485, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2653, Total reward=-0.2, Steps=18492, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2654, Total reward=0.9, Steps=18496, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2655, Total reward=-1, Steps=18499, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2656, Total reward=-0.4, Steps=18508, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2657, Total reward=1, Steps=18512, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2658, Total reward=0.9, Steps=18517, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2659, Total reward=-0.1, Steps=18523, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2660, Total reward=1, Steps=18527, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2661, Total reward=-0.1, Steps=18533, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2662, Total reward=-1, Steps=18536, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2663, Total reward=0.9, Steps=18541, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2664, Total reward=0.9, Steps=18546, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2665, Total reward=-1, Steps=18549, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2666, Total reward=0, Steps=18554, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2667, Total reward=-1.1, Steps=18558, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2668, Total reward=1, Steps=18562, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2669, Total reward=-0.5, Steps=18572, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2670, Total reward=-1, Steps=18575, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2671, Total reward=-0.3, Steps=18583, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2672, Total reward=-0.2, Steps=18590, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2673, Total reward=1, Steps=18594, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2674, Total reward=1, Steps=18597, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2675, Total reward=0.8, Steps=18603, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2676, Total reward=1, Steps=18607, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2677, Total reward=-0.1, Steps=18613, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2678, Total reward=0.9, Steps=18618, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2679, Total reward=0.8, Steps=18624, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2680, Total reward=0.9, Steps=18629, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2681, Total reward=1, Steps=18633, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2682, Total reward=1, Steps=18637, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2683, Total reward=0.9, Steps=18642, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2684, Total reward=-0.2, Steps=18649, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2685, Total reward=1, Steps=18653, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2686, Total reward=0, Steps=18658, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2687, Total reward=1, Steps=18662, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2688, Total reward=0.8, Steps=18669, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2689, Total reward=1, Steps=18673, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2690, Total reward=1, Steps=18677, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2691, Total reward=-0.5, Steps=18687, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2692, Total reward=1, Steps=18691, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2693, Total reward=0.9, Steps=18696, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2694, Total reward=-0.1, Steps=18702, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2695, Total reward=0, Steps=18707, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2696, Total reward=1, Steps=18711, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2697, Total reward=1, Steps=18715, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2698, Total reward=0, Steps=18720, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2699, Total reward=0, Steps=18725, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2700, Total reward=-0.4, Steps=18734, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2701, Total reward=1, Steps=18738, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2702, Total reward=-1.1, Steps=18742, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2703, Total reward=1, Steps=18746, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2704, Total reward=-1, Steps=18749, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2705, Total reward=0.9, Steps=18754, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2706, Total reward=0.8, Steps=18760, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2707, Total reward=-0.1, Steps=18766, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2708, Total reward=-0.3, Steps=18774, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2709, Total reward=1, Steps=18778, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2710, Total reward=-0.3, Steps=18786, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2711, Total reward=-2.0, Steps=18801, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2712, Total reward=0.8, Steps=18808, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2713, Total reward=0, Steps=18813, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2714, Total reward=1, Steps=18817, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2715, Total reward=-0.3, Steps=18825, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2716, Total reward=-1.2, Steps=18830, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2717, Total reward=-0.8, Steps=18843, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2718, Total reward=-0.1, Steps=18849, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2719, Total reward=0, Steps=18854, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2720, Total reward=-0.4, Steps=18863, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2721, Total reward=1, Steps=18867, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2722, Total reward=1, Steps=18871, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2723, Total reward=1, Steps=18875, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2724, Total reward=1, Steps=18879, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2725, Total reward=1, Steps=18883, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2726, Total reward=-1, Steps=18886, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2727, Total reward=-0.8, Steps=18899, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2728, Total reward=-0.1, Steps=18905, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2729, Total reward=1, Steps=18909, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2730, Total reward=-0.4, Steps=18918, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2731, Total reward=-1, Steps=18921, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2732, Total reward=0.9, Steps=18927, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2733, Total reward=1, Steps=18931, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2734, Total reward=-1, Steps=18934, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2735, Total reward=-1, Steps=18937, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2736, Total reward=-0.7, Steps=18949, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2737, Total reward=0.9, Steps=18954, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2738, Total reward=0, Steps=18959, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2739, Total reward=0.8, Steps=18965, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2740, Total reward=1, Steps=18969, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2741, Total reward=0, Steps=18974, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2742, Total reward=0, Steps=18979, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2743, Total reward=0.9, Steps=18984, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2744, Total reward=0.7, Steps=18991, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2745, Total reward=-0.2, Steps=18998, Training iteration=9\u001b[0m\n",
      "\u001b[34m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=2745, Total reward=1, Steps=19000, Training iteration=9\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=2745, Total reward=1, Steps=19000, Training iteration=9\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=2745, Total reward=1, Steps=19000, Training iteration=9\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=2745, Total reward=-2.0, Steps=19000, Training iteration=9\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=2745, Total reward=1, Steps=19000, Training iteration=9\u001b[0m\n",
      "\u001b[34m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = 0.4\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2746, Total reward=-2.0, Steps=19014, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2747, Total reward=1, Steps=19018, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2748, Total reward=0.9, Steps=19023, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2749, Total reward=1, Steps=19027, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2750, Total reward=-1, Steps=19030, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2751, Total reward=-0.2, Steps=19037, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2752, Total reward=0.9, Steps=19042, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2753, Total reward=0.9, Steps=19047, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2754, Total reward=1, Steps=19050, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2755, Total reward=-0.6, Steps=19061, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2756, Total reward=-0.1, Steps=19067, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2757, Total reward=-0.1, Steps=19073, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2758, Total reward=1, Steps=19077, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2759, Total reward=-1.4, Steps=19085, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2760, Total reward=0.9, Steps=19091, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2761, Total reward=1, Steps=19095, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2762, Total reward=-1.1, Steps=19099, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2763, Total reward=0.8, Steps=19105, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2764, Total reward=0, Steps=19110, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2765, Total reward=0.9, Steps=19115, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2766, Total reward=-1.1, Steps=19120, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2767, Total reward=0.9, Steps=19125, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2768, Total reward=-0.1, Steps=19131, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2769, Total reward=1, Steps=19135, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2770, Total reward=1, Steps=19139, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2771, Total reward=1, Steps=19143, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2772, Total reward=0.9, Steps=19148, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2773, Total reward=0, Steps=19153, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2774, Total reward=-1.6, Steps=19163, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2775, Total reward=1, Steps=19167, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2776, Total reward=-0.1, Steps=19173, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2777, Total reward=-1, Steps=19176, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2778, Total reward=0.9, Steps=19181, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2779, Total reward=1, Steps=19185, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2780, Total reward=0, Steps=19190, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2781, Total reward=1, Steps=19194, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2782, Total reward=-1, Steps=19198, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2783, Total reward=1, Steps=19202, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2784, Total reward=0.9, Steps=19206, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2785, Total reward=0.9, Steps=19211, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2786, Total reward=-1.1, Steps=19216, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2787, Total reward=0, Steps=19221, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2788, Total reward=1, Steps=19225, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2789, Total reward=0, Steps=19230, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2790, Total reward=1, Steps=19234, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2791, Total reward=1, Steps=19238, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2792, Total reward=1, Steps=19242, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2793, Total reward=1, Steps=19246, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2794, Total reward=1, Steps=19250, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2795, Total reward=-0.1, Steps=19256, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2796, Total reward=1, Steps=19260, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2797, Total reward=-0.1, Steps=19266, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2798, Total reward=1, Steps=19270, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2799, Total reward=1, Steps=19274, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2800, Total reward=1, Steps=19278, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2801, Total reward=-1, Steps=19282, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2802, Total reward=1, Steps=19286, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2803, Total reward=-1, Steps=19289, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2804, Total reward=0, Steps=19294, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2805, Total reward=1, Steps=19298, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2806, Total reward=1, Steps=19302, Training iteration=9\u001b[0m\n",
      "\u001b[34mCheckpoint> Saving in path=['/opt/ml/output/data/checkpoint/19_Step-19302.ckpt.main_level.agent.main.online.onnx', '/opt/ml/output/data/checkpoint/19_Step-19302.ckpt.main_level.agent.main.online']\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2807, Total reward=-0.3, Steps=19310, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2808, Total reward=1, Steps=19314, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2809, Total reward=-1, Steps=19318, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2810, Total reward=0.9, Steps=19323, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2811, Total reward=0, Steps=19328, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2812, Total reward=1, Steps=19332, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2813, Total reward=0.9, Steps=19337, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2814, Total reward=0.8, Steps=19343, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2815, Total reward=1, Steps=19347, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2816, Total reward=0.9, Steps=19352, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2817, Total reward=-0.2, Steps=19359, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2818, Total reward=0, Steps=19364, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2819, Total reward=1, Steps=19368, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2820, Total reward=0, Steps=19373, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2821, Total reward=-1, Steps=19376, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2822, Total reward=-1, Steps=19380, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2823, Total reward=1, Steps=19384, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2824, Total reward=-1, Steps=19387, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2825, Total reward=1, Steps=19391, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2826, Total reward=1, Steps=19395, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2827, Total reward=1, Steps=19399, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2828, Total reward=0.9, Steps=19404, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2829, Total reward=-0.2, Steps=19411, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2830, Total reward=-0.5, Steps=19421, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2831, Total reward=0.9, Steps=19427, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2832, Total reward=1, Steps=19431, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2833, Total reward=0.5, Steps=19440, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2834, Total reward=-0.6, Steps=19451, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2835, Total reward=-1.1, Steps=19456, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2836, Total reward=-0.2, Steps=19463, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2837, Total reward=0.3, Steps=19474, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2838, Total reward=1, Steps=19478, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2839, Total reward=-1.1, Steps=19483, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2840, Total reward=1, Steps=19487, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2841, Total reward=1, Steps=19491, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2842, Total reward=-2.1, Steps=19507, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2843, Total reward=0, Steps=19512, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2844, Total reward=-0.2, Steps=19519, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2845, Total reward=0.1, Steps=19532, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2846, Total reward=1, Steps=19536, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2847, Total reward=-0.1, Steps=19542, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2848, Total reward=1, Steps=19546, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2849, Total reward=0.9, Steps=19551, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2850, Total reward=-1.1, Steps=19556, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2851, Total reward=1, Steps=19560, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2852, Total reward=-1, Steps=19563, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2853, Total reward=0.8, Steps=19569, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2854, Total reward=1, Steps=19573, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2855, Total reward=1, Steps=19577, Training iteration=9\u001b[0m\n",
      "\n",
      "2024-08-15 15:37:04 Uploading - Uploading generated training model\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2856, Total reward=0, Steps=19582, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2857, Total reward=0.9, Steps=19587, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2858, Total reward=0.8, Steps=19593, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2859, Total reward=0.9, Steps=19598, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2860, Total reward=-0.9, Steps=19612, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2861, Total reward=-1, Steps=19616, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2862, Total reward=0.8, Steps=19622, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2863, Total reward=1, Steps=19626, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2864, Total reward=-0.2, Steps=19633, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2865, Total reward=1, Steps=19637, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2866, Total reward=-1.1, Steps=19642, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2867, Total reward=1, Steps=19646, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2868, Total reward=1, Steps=19650, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2869, Total reward=-1, Steps=19653, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2870, Total reward=-1, Steps=19657, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2871, Total reward=-0.3, Steps=19665, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2872, Total reward=-1, Steps=19668, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2873, Total reward=-0.5, Steps=19678, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2874, Total reward=-0.3, Steps=19686, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2875, Total reward=0, Steps=19691, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2876, Total reward=1, Steps=19695, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2877, Total reward=-0.3, Steps=19703, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2878, Total reward=-1, Steps=19706, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2879, Total reward=-0.1, Steps=19712, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2880, Total reward=-0.5, Steps=19722, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2881, Total reward=-1.4, Steps=19730, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2882, Total reward=0, Steps=19735, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2883, Total reward=-0.2, Steps=19742, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2884, Total reward=1, Steps=19746, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2885, Total reward=1, Steps=19750, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2886, Total reward=0.8, Steps=19756, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2887, Total reward=0, Steps=19761, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2888, Total reward=-1, Steps=19764, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2889, Total reward=0.8, Steps=19770, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2890, Total reward=-1.1, Steps=19775, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2891, Total reward=0.9, Steps=19780, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2892, Total reward=0.9, Steps=19785, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2893, Total reward=0, Steps=19790, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2894, Total reward=-1, Steps=19793, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2895, Total reward=1, Steps=19797, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2896, Total reward=1, Steps=19801, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2897, Total reward=0, Steps=19806, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2898, Total reward=0, Steps=19811, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2899, Total reward=-0.2, Steps=19818, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2900, Total reward=0.7, Steps=19825, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2901, Total reward=-0.2, Steps=19832, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2902, Total reward=1, Steps=19836, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2903, Total reward=0, Steps=19841, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2904, Total reward=0, Steps=19846, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2905, Total reward=-0.3, Steps=19854, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2906, Total reward=1, Steps=19858, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2907, Total reward=1, Steps=19862, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2908, Total reward=1, Steps=19866, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2909, Total reward=1, Steps=19870, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2910, Total reward=0, Steps=19875, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2911, Total reward=1, Steps=19879, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2912, Total reward=1, Steps=19883, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2913, Total reward=0, Steps=19888, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2914, Total reward=0.9, Steps=19893, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2915, Total reward=-1, Steps=19896, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2916, Total reward=0.6, Steps=19904, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2917, Total reward=0.8, Steps=19910, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2918, Total reward=-1, Steps=19913, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2919, Total reward=0.9, Steps=19918, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2920, Total reward=-1, Steps=19921, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2921, Total reward=0.9, Steps=19926, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2922, Total reward=-0.3, Steps=19934, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2923, Total reward=-2.0, Steps=19949, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2924, Total reward=-1, Steps=19952, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2925, Total reward=1, Steps=19956, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2926, Total reward=1, Steps=19959, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2927, Total reward=0, Steps=19964, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2928, Total reward=1, Steps=19968, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2929, Total reward=1, Steps=19972, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2930, Total reward=1, Steps=19976, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2931, Total reward=-0.1, Steps=19982, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2932, Total reward=-0.2, Steps=19989, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2933, Total reward=1, Steps=19993, Training iteration=9\u001b[0m\n",
      "\u001b[34mTraining> Name=main_level/agent, Worker=0, Episode=2934, Total reward=1, Steps=19997, Training iteration=9\u001b[0m\n",
      "\u001b[34m## agent: Starting evaluation phase\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=2934, Total reward=0, Steps=20000, Training iteration=9\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=2934, Total reward=1, Steps=20000, Training iteration=9\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=2934, Total reward=1, Steps=20000, Training iteration=9\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=2934, Total reward=1, Steps=20000, Training iteration=9\u001b[0m\n",
      "\u001b[34mTesting> Name=main_level/agent, Worker=0, Episode=2934, Total reward=1, Steps=20000, Training iteration=9\u001b[0m\n",
      "\u001b[34m## agent: Finished evaluation phase. Success rate = 0.0, Avg Total Reward = 0.8\u001b[0m\n",
      "\u001b[34mONNX correction applied to discrete PPO agent.\u001b[0m\n",
      "\u001b[34m2024-08-15 15:36:57,396 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2024-08-15 15:37:22 Completed - Training job completed\n",
      "Training seconds: 325\n",
      "Billable seconds: 325\n"
     ]
    }
   ],
   "source": [
    "estimator = RLEstimator(\n",
    "    source_dir=\"src\",\n",
    "    entry_point=\"train-coach.py\",\n",
    "    dependencies=[\"common/sagemaker_rl\"],\n",
    "    toolkit=RLToolkit.COACH,\n",
    "    toolkit_version=\"0.11.0\",\n",
    "    framework=RLFramework.MXNET,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    output_path=\"s3://{}/\".format(bucket),\n",
    "    base_job_name=\"DEMO-rl-tic-tac-toe\",\n",
    "    hyperparameters={\"save_model\": 1},\n",
    ")\n",
    "\n",
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store intermediate training output and model checkpoints\n",
    "\n",
    "The output from the training job above is stored on S3. The intermediate folder contains gifs and metadata of the training. We'll need these metadata for metrics visualization and model evaluations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Cell 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job name: DEMO-rl-tic-tac-toe-2024-08-15-15-30-30-258\n",
      "S3 job path: s3://lab-data-bucket-725001333577-54717fe0/DEMO-rl-tic-tac-toe-2024-08-15-15-30-30-258\n",
      "Output.tar.gz location: s3://lab-data-bucket-725001333577-54717fe0/DEMO-rl-tic-tac-toe-2024-08-15-15-30-30-258/output/output.tar.gz\n",
      "Intermediate folder path: s3://lab-data-bucket-725001333577-54717fe0/DEMO-rl-tic-tac-toe-2024-08-15-15-30-30-258/output/intermediate/\n",
      "Create local folder /tmp/DEMO-rl-tic-tac-toe-2024-08-15-15-30-30-258\n"
     ]
    }
   ],
   "source": [
    "job_name = estimator._current_job_name\n",
    "print(\"Job name: {}\".format(job_name))\n",
    "\n",
    "s3_url = \"s3://{}/{}\".format(bucket, job_name)\n",
    "\n",
    "output_tar_key = \"{}/output/output.tar.gz\".format(job_name)\n",
    "\n",
    "intermediate_folder_key = \"{}/output/intermediate/\".format(job_name)\n",
    "output_url = \"s3://{}/{}\".format(bucket, output_tar_key)\n",
    "intermediate_url = \"s3://{}/{}\".format(bucket, intermediate_folder_key)\n",
    "\n",
    "print(\"S3 job path: {}\".format(s3_url))\n",
    "print(\"Output.tar.gz location: {}\".format(output_url))\n",
    "print(\"Intermediate folder path: {}\".format(intermediate_url))\n",
    "\n",
    "tmp_dir = \"/tmp/{}\".format(job_name)\n",
    "os.system(\"mkdir {}\".format(tmp_dir))\n",
    "print(\"Create local folder {}\".format(tmp_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "### Plot metrics for training job\n",
    "\n",
    "We can pull the reward metric of the training and plot it to see the performance of the model over time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Cell 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:matplotlib.font_manager:generated new fontManager\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for s3://lab-data-bucket-725001333577-54717fe0/DEMO-rl-tic-tac-toe-2024-08-15-15-30-30-258/output/intermediate/worker_0.simple_rl_graph.main_level.main_level.agent_0.csv...\n",
      "Downloading DEMO-rl-tic-tac-toe-2024-08-15-15-30-30-258/output/intermediate/worker_0.simple_rl_graph.main_level.main_level.agent_0.csv\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"common\")\n",
    "import pandas as pd\n",
    "from misc import wait_for_s3_object\n",
    "\n",
    "csv_file_name = \"worker_0.simple_rl_graph.main_level.main_level.agent_0.csv\"\n",
    "key = os.path.join(intermediate_folder_key, csv_file_name)\n",
    "wait_for_s3_object(bucket, key, tmp_dir)\n",
    "\n",
    "csv_file = \"{}/{}\".format(tmp_dir, csv_file_name)\n",
    "df = pd.read_csv(csv_file)\n",
    "df = df.dropna(subset=[\"Training Reward\"])\n",
    "x_axis = \"Episode #\"\n",
    "y_axis = \"Training Reward\"\n",
    "\n",
    "if len(df) > 0:\n",
    "    plt = df.plot(x=x_axis, y=y_axis, figsize=(12, 5), legend=True, style=\"b-\")\n",
    "    plt.set_ylabel(y_axis)\n",
    "    plt.set_xlabel(x_axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Plot you can see the training reward over the number of episodes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Deploy\n",
    "\n",
    "Now we are testing for more tangible approach of testing the trained agent by playing against it ourselves.  To do that, we'll first deploy the agent to a realtime endpoint to get predictions.\n",
    "\n",
    "### Inference\n",
    "\n",
    "Our deployment code:\n",
    "1. Unpacks the ONNX model output and prepares it for inference in `model_fn`\n",
    "1. Generates predictions from our network, given state (a flattened tic-tac-toe board) in `transform_fn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Cell 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mmxnet\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mmx\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mmxnet\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m gluon, nd\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mmxnet\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mcontrib\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m onnx \u001b[34mas\u001b[39;49;00m onnx_mxnet\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "\u001b[33m    Load the onnx model. Called once when hosting service starts.\u001b[39;49;00m\n",
      "\u001b[33m\u001b[39;49;00m\n",
      "\u001b[33m    :param: model_dir The directory where model files are stored.\u001b[39;49;00m\n",
      "\u001b[33m    :return: a model\u001b[39;49;00m\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    onnx_path = os.path.join(model_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel.onnx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    ctx = mx.cpu()  \u001b[37m# todo: pass into function\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# load onnx model symbol and parameters\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    sym, arg_params, aux_params = onnx_mxnet.import_model(onnx_path)\u001b[37m\u001b[39;49;00m\n",
      "    model_metadata = onnx_mxnet.get_model_metadata(onnx_path)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# first index is name, second index is shape\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    input_names = [inputs[\u001b[34m0\u001b[39;49;00m] \u001b[34mfor\u001b[39;49;00m inputs \u001b[35min\u001b[39;49;00m model_metadata.get(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_tensor_data\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)]\u001b[37m\u001b[39;49;00m\n",
      "    input_symbols = [mx.sym.var(i) \u001b[34mfor\u001b[39;49;00m i \u001b[35min\u001b[39;49;00m input_names]\u001b[37m\u001b[39;49;00m\n",
      "    net = gluon.nn.SymbolBlock(outputs=sym, inputs=input_symbols)\u001b[37m\u001b[39;49;00m\n",
      "    net_params = net.collect_params()\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# set parameters (on correct context)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mfor\u001b[39;49;00m param \u001b[35min\u001b[39;49;00m arg_params:\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mif\u001b[39;49;00m param \u001b[35min\u001b[39;49;00m net_params:\u001b[37m\u001b[39;49;00m\n",
      "            net_params[param]._load_init(arg_params[param], ctx=ctx)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mfor\u001b[39;49;00m param \u001b[35min\u001b[39;49;00m aux_params:\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mif\u001b[39;49;00m param \u001b[35min\u001b[39;49;00m net_params:\u001b[37m\u001b[39;49;00m\n",
      "            net_params[param]._load_init(aux_params[param], ctx=ctx)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# hybridize for increase performance\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    net.hybridize()\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m net\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtransform_fn\u001b[39;49;00m(net, data, input_content_type, output_content_type):\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "\u001b[33m    Transform a request using the Gluon model. Called once per request.\u001b[39;49;00m\n",
      "\u001b[33m\u001b[39;49;00m\n",
      "\u001b[33m    :param net: Gluon Model.\u001b[39;49;00m\n",
      "\u001b[33m    :param data: The request payload.\u001b[39;49;00m\n",
      "\u001b[33m    :param input_content_type: The request content type.\u001b[39;49;00m\n",
      "\u001b[33m    :param output_content_type: The (desired) response content type.\u001b[39;49;00m\n",
      "\u001b[33m    :return: response payload and content type.\u001b[39;49;00m\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    input_list = json.loads(data)\u001b[37m\u001b[39;49;00m\n",
      "    input_nd = mx.nd.array(input_list).expand_dims(\u001b[34m0\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    output = net(input_nd)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m \u001b[36mtype\u001b[39;49;00m(output) == \u001b[36mlist\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "        output_list = [o.asnumpy().tolist() \u001b[34mfor\u001b[39;49;00m o \u001b[35min\u001b[39;49;00m output]\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34melif\u001b[39;49;00m \u001b[36mtype\u001b[39;49;00m(output) == mx.nd.NDArray:\u001b[37m\u001b[39;49;00m\n",
      "        output_list = [output.asnumpy().tolist()]\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m json.dumps(output_list), output_content_type\u001b[37m\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize ./src/deploy-coach.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Endpoint\n",
    "\n",
    "Now we'll actually create a SageMaker endpoint to call for predictions.\n",
    "\n",
    "*Note, this step could be replaced by importing the ONNX model into the notebook environment.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Cell 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: DEMO-rl-tic-tac-toe-2024-08-15-15-43-01-032\n",
      "INFO:sagemaker:Creating endpoint-config with name DEMO-rl-tic-tac-toe-2024-08-15-15-43-01-032\n",
      "INFO:sagemaker:Creating endpoint with name DEMO-rl-tic-tac-toe-2024-08-15-15-43-01-032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1, instance_type=\"ml.m5.xlarge\", entry_point=\"deploy-coach.py\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEMO-rl-tic-tac-toe-2024-08-15-15-43-01-032\n"
     ]
    }
   ],
   "source": [
    "print(predictor.endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Play \n",
    "\n",
    "Let's play our agent.  After running the cell below, just click on one the boxes to make your move.  To restart the game, simply execute the cell again.\n",
    "\n",
    "*This cell uses the `TicTacToeGame` class from `tic_tac_toe_game.py` script to build an extremely basic tic-tac-toe app within a Jupyter notebook.  The opponents moves are generated by invoking the `predictor` passed at initialization.  Please refer to the code for additional details.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Cell 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23674c7328d440548a3c66935303ae8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(Button(layout=Layout(height='75px', width='75px'), style=ButtonSt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = TicTacToeGame(predictor)\n",
    "t.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Wrap Up\n",
    "\n",
    "In this notebook we trained a reinforcement learning agent to play a simple game of tic-tac-toe, using a custom Gym environment.  It could be built upon to solve other problems or improved by:\n",
    "\n",
    "- Training for more episodes\n",
    "- Using a different reinforcement learning algorithm\n",
    "- Tuning hyperparameters for improved performance\n",
    "- Or how about a nice game of [global thermonuclear war](https://youtu.be/s93KC4AGKnY?t=41)?\n",
    "\n",
    "Let's finish by cleaning up our endpoint to prevent any persistent costs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Cell 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "notice": "Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved. Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
